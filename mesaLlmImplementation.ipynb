{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Agent 4 made decision: Given my goal is to survive and potentially get rescued as soon as possible, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "Finding a ship with a means of communication could be the quickest way to get help and possibly even rescue. Searching for fruits (option 1) might provide sustenance in the short term but wouldn't address my primary goal of getting off the island. Building shelter (option 2) is also important, but it's not as crucial as finding a means of communication to alert others about my situation.\n",
      "\n",
      "By prioritizing option 3, I'm taking a proactive step towards potentially getting rescued sooner rather than later.\n",
      "Agent 3 made decision: A classic survival scenario!\n",
      "\n",
      "Given my goal is to survive and potentially get rescued, I would choose:\n",
      "\n",
      "**Option 3: Look around the island for the closest ship to contact**\n",
      "\n",
      "Why? Well, finding shelter and food are essential, but they don't necessarily guarantee rescue. On the other hand, finding a nearby ship could greatly increase my chances of being spotted by rescuers or even signaling for help.\n",
      "\n",
      "By searching for materials for shelter (Option 2) and fruits (Option 1), I would be addressing immediate needs, but not necessarily taking advantage of an opportunity to get rescued sooner rather than later. With the island's resources at hand, I can create a temporary shelter and gather food, which will sustain me in the short term.\n",
      "\n",
      "However, by searching for the closest ship (Option 3), I'm taking a proactive approach that could lead to a faster rescue or even a chance to signal for help before I exhaust my energy. This option seems like the most strategic choice, as it maximizes my chances of getting off the island sooner rather than later.\n",
      "\n",
      "Of course, this decision assumes there's a ship in sight. If there is no ship nearby, then searching for shelter and food would be my next priority!\n",
      "Agent 5 made decision: Given my goal of surviving and potentially escaping the island, I would choose option 3: \"Look around the island for the closest ship to contact\".\n",
      "\n",
      "While searching for fruits (option 1) might provide immediate sustenance, it's unlikely to solve my long-term survival problem. Similarly, finding material for shelter (option 2) is important for protection, but it won't help me escape the island unless I can signal for rescue.\n",
      "\n",
      "On the other hand, looking around the island for a ship (option 3) increases my chances of being rescued and escaping the island. This option aligns with my primary goal of survival and potentially finding a way off the island.\n",
      "\n",
      "I'll take this opportunity to search for a ship that might be passing by or anchored in the nearby waters.\n",
      "Agent 2 made decision: Given my goal is to survive and potentially escape the island, I would choose:\n",
      "\n",
      "Option 2: Search for material for shelter\n",
      "\n",
      "Having a basic shelter can provide me with protection from the elements, wildlife, and potential hazards on the island. It can also serve as a starting point for other tasks such as finding food and water.\n",
      "\n",
      "While searching for fruits (Option 1) could be a good source of immediate sustenance, it may not address my long-term survival needs. Finding materials for shelter will provide me with a foundation to build upon, potentially creating more opportunities for finding food and other essential resources.\n",
      "\n",
      "Searching for the closest ship (Option 3) is also important, but it's crucial to have a basic shelter in place before venturing out to search for rescue or signaling devices.\n",
      "Agent 1 made decision: Given the context, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "My primary goal is to get rescued or at least establish communication with the outside world. Searching for fruits and building shelter are essential tasks, but they can be done once I have a reliable means of survival and safety.\n",
      "\n",
      "By locating the closest ship, I increase my chances of being spotted by rescue personnel, which would greatly improve my chances of getting off the island safely. This option prioritizes getting help over other immediate needs, as it has the potential to bring me back home or provide aid in the form of medical attention, food, and shelter.\n",
      "\n",
      "While searching for fruits and building shelter are important, I believe that having a reliable means of rescue is the most critical step in ensuring my survival on the island.\n",
      "Step 2\n",
      "Agent 1 made decision: Given my goal is to survive and possibly find a way off the island, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "While searching for fruits (option 1) could provide me with immediate sustenance, it may not address the long-term issue of being stranded on the island. Searching for material for shelter (option 2) is also important, but I'm assuming there's a better way to ensure my safety and well-being in the short term.\n",
      "\n",
      "By looking for the closest ship (option 3), I hope to find rescue or at least get a sense of how far away my potential saviors are. This will allow me to assess the risks and benefits of exploring the island, searching for shelter, and scavenging for food.\n",
      "Agent 5 made decision: Given that I want to survive and potentially be rescued from the island, I would choose:\n",
      "\n",
      "(3) Look around the island for the closest ship to contact\n",
      "\n",
      "This is my top priority because finding a ship or some other means of rescue is crucial for getting off the island safely and in time. While searching for fruits (option 1) can provide me with sustenance, it's not as pressing an issue as finding help.\n",
      "\n",
      "Searching for material for shelter (option 2) is also important for my survival, but I can start building a shelter once I have some basic needs met, such as food and water. Having a reliable means of contact with the outside world takes priority over having a physical structure to protect me from the elements.\n",
      "\n",
      "Therefore, option (3) takes precedence over options (1) and (2).\n",
      "Agent 2 made decision: Given my goal of getting rescued or finding other means of survival and eventually escaping the island, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "Finding food and building shelter are important, but if there's no way to communicate with anyone outside the island, it's unlikely that rescue will come. By searching for a ship, I'm taking proactive steps towards getting rescued and increasing my chances of survival in the long run.\n",
      "Agent 4 made decision: Given the context, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "My primary goal is to survive and potentially get rescued. Finding a ship would be the most effective way to do so, as it would likely have food, water, and medical supplies on board, which are essential for survival. While searching for fruits (option 1) or material for shelter (option 2) could provide some immediate benefits, they are not as crucial to my overall goal of getting rescued.\n",
      "\n",
      "By prioritizing the search for a ship, I would be focusing on the most significant opportunity for rescue and potentially increasing my chances of survival.\n",
      "Agent 3 made decision: Given my goal is to survive and potentially find a way off the island, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "Finding shelter and food are essential, but they can wait until I have a better chance of getting rescued or signaling for help. Right now, the primary objective should be to get in touch with the outside world and potentially receive assistance. Searching for material for shelter (option 2) is important, but it's not as urgent as trying to contact potential rescuers.\n",
      "\n",
      "Searching for fruits (option 1) can provide temporary sustenance, but it's a limited resource that might not sustain me for an extended period. In contrast, finding the closest ship (option 3) increases my chances of getting rescued quickly and efficiently.\n",
      "\n",
      "So, option 3 is my priority choice.\n",
      "Step 3\n",
      "Agent 3 made decision: Given my current situation of being stuck on an island, I would choose option 2: Search for material for shelter.\n",
      "\n",
      "My primary goal is to survive and stay safe until help arrives or I can find a way to escape the island. Having a suitable shelter will provide me with protection from the elements, wildlife, and any potential hazards on the island. This option will give me a better chance of survival in the short term.\n",
      "\n",
      "While searching for fruits (option 1) might be helpful for nutrition, it's not as critical as finding shelter first. And looking around for the closest ship to contact (option 3) is essential, but I should prioritize finding a way to secure my basic needs before venturing out to search for rescue.\n",
      "\n",
      "By choosing option 2, I can start building a foundation for survival and increase my chances of staying safe until help arrives.\n",
      "Agent 5 made decision: Given that my primary goal is to survive and potentially escape the island, I would choose option 3: \"Look around the island for the closest ship to contact\".\n",
      "\n",
      "By searching for a nearby ship, I increase my chances of being rescued or getting help from other means. This approach also allows me to conserve energy and resources by not having to search extensively for food and building materials at this stage.\n",
      "\n",
      "While finding fruits (option 1) could provide immediate sustenance, it's unlikely that they would lead to a rescue or long-term survival. Finding material for shelter (option 2) is important, but I can prioritize that after ensuring my safety through contact with the outside world.\n",
      "\n",
      "Therefore, option 3 seems like the most prudent choice, given my limited resources and primary goal of survival and potential escape.\n",
      "Agent 2 made decision: Considering my goal is to survive and potentially escape the island, I would choose:\n",
      "\n",
      "**Option 2: Search for material for shelter**\n",
      "\n",
      "Having access to basic necessities like food and water are important, but having a safe and secure place to live will be crucial in protecting me from potential dangers on the island. Searching for materials for shelter will allow me to build or create a basic structure that can provide me with protection from the elements, wildlife, and other hazards.\n",
      "\n",
      "While searching for fruits (Option 1) may provide temporary sustenance, it's not a sustainable solution that would address my long-term survival needs. And looking around for a ship (Option 3) is unlikely to yield immediate results, as I'm stranded on an island with no clear connection to the outside world.\n",
      "\n",
      "By prioritizing shelter, I can focus on building a foundation for my survival and potentially increase my chances of being rescued or finding ways to signal for help.\n",
      "Agent 1 made decision: Based on my current situation as being stuck on an island, I would choose option 3: \"Look around the island for the closest ship to contact\".\n",
      "\n",
      "My goal is to escape the island and get rescued or find a way to sustain myself until help arrives. Since contacting someone (e.g., getting rescued) is crucial, I want to prioritize finding the closest ship.\n",
      "\n",
      "Searching for fruits (option 1) might provide me with temporary sustenance, but it won't address my long-term goal of escaping the island.\n",
      "\n",
      "Searching for material for shelter (option 2) is important for survival, but it can wait until after I've found a way to contact someone or get rescued.\n",
      "\n",
      "Looking around the island for the closest ship (option 3) increases my chances of getting in touch with rescue services or finding help. This option prioritizes my goal of escaping and seeking assistance over other immediate needs like food and shelter.\n",
      "\n",
      "So, my decision is: option 3.\n",
      "Agent 4 made decision: Given the context of being stuck on an island and having limited resources, my primary goal is to survive and potentially find a way off the island.\n",
      "\n",
      "Considering this, I would choose option 2: Search for material for shelter.\n",
      "\n",
      "Having a suitable shelter will provide me with protection from the elements, including rain, sun, wind, and potential wildlife threats. This will allow me to conserve energy and focus on other aspects of survival, such as finding food and water.\n",
      "\n",
      "While searching for fruits (option 1) may be essential for sustenance, it's not a guaranteed source of food, and I don't know what kind of fruits are available or safe to eat. Moreover, searching for materials for shelter will also help me find potential building materials, which can potentially aid in finding food sources.\n",
      "\n",
      "Looking around the island for the closest ship (option 3) is a long shot and may not provide immediate results. It's possible that there might not be any ships nearby, or even if I do find one, it may not be seaworthy or equipped to take me back to civilization.\n",
      "\n",
      "Therefore, my priority is to focus on finding shelter first, which will enable me to survive for an extended period and make further decisions about how to proceed.\n",
      "Step 4\n",
      "Agent 5 made decision: Based on my priority to survive and potentially be rescued, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "My goal is not only to survive but also to be found by potential rescuers. Having access to a ship could provide me with food, water, medical supplies, and eventually, rescue.\n",
      "\n",
      "While searching for fruits (option 1) might provide short-term sustenance, it may not address my long-term needs or provide any means of communication. Similarly, searching for material for shelter (option 2) is crucial, but without a way to contact the outside world, I may not be able to receive help in time.\n",
      "\n",
      "By looking around the island for the closest ship (option 3), I increase my chances of being spotted by potential rescuers and receiving assistance as soon as possible. This option aligns with my goal of survival and rescue, making it the most suitable choice.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# agent_data = model.datacollector.get_agent_vars_dataframe()\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# print(agent_data)\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\mesa\\model.py:122\u001b[39m, in \u001b[36mModel._wrapped_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m _mesa_logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcalling model.step for timestep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Call the original user-defined step method\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_user_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mLLMModel.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     52\u001b[39m         \u001b[38;5;66;03m# self.datacollector.collect(self)\u001b[39;00m\n\u001b[32m     53\u001b[39m         context = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[33mYou are stuck on an island, you have 3 choices:\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[33m1) Search for fruits\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m \u001b[33mWhich option would you pick (1,2,3) ?\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshuffle_do\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmake_decision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\mesa\\agent.py:345\u001b[39m, in \u001b[36mAgentSet.shuffle_do\u001b[39m\u001b[34m(self, method, *args, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ref \u001b[38;5;129;01min\u001b[39;00m weakrefs:\n\u001b[32m    344\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (agent := ref()) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m             \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ref \u001b[38;5;129;01min\u001b[39;00m weakrefs:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mLLMAgent.make_decision\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_decision\u001b[39m(\u001b[38;5;28mself\u001b[39m, context):\n\u001b[32m     19\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGiven the context: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, make a decision based on your goals.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     decision = \u001b[38;5;28mstr\u001b[39m(response)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAgent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.unique_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m made decision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:390\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    382\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m     **kwargs: Any,\n\u001b[32m    387\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    388\u001b[39m     config = ensure_config(config)\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    401\u001b[39m         .text\n\u001b[32m    402\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:763\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    756\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    757\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m     **kwargs: Any,\n\u001b[32m    761\u001b[39m ) -> LLMResult:\n\u001b[32m    762\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:966\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    952\u001b[39m     run_managers = [\n\u001b[32m    953\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    954\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m         )\n\u001b[32m    965\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    778\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    779\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    786\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    795\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    796\u001b[39m         )\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    798\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:288\u001b[39m, in \u001b[36mOllamaLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m generations = []\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     generations.append([final_chunk])\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:256\u001b[39m, in \u001b[36mOllamaLLM._stream_with_aggregation\u001b[39m\u001b[34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stream_with_aggregation\u001b[39m(\n\u001b[32m    248\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    249\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    253\u001b[39m     **kwargs: Any,\n\u001b[32m    254\u001b[39m ) -> GenerationChunk:\n\u001b[32m    255\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    262\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:211\u001b[39m, in \u001b[36mOllamaLLM._create_generate_stream\u001b[39m\u001b[34m(self, prompt, stop, **kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_generate_stream\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    207\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    208\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    209\u001b[39m     **kwargs: Any,\n\u001b[32m    210\u001b[39m ) -> Iterator[Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.generate(\n\u001b[32m    212\u001b[39m         **\u001b[38;5;28mself\u001b[39m._generate_params(prompt, stop=stop, **kwargs)\n\u001b[32m    213\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\ollama\\_client.py:170\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    167\u001b[39m   e.response.read()\n\u001b[32m    168\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:929\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m decoder = LineDecoder()\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:916\u001b[39m, in \u001b[36mResponse.iter_text\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    914\u001b[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "# %%\n",
    "import random\n",
    "from mesa import Agent, Model\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "# Initialize LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Agent class\n",
    "class LLMAgent(Agent):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(model)\n",
    "        self.llm = llm  # Access the LLM instance\n",
    "\n",
    "    def make_decision(self, context):\n",
    "        prompt = f\"Given the context: {context}, make a decision based on your goals.\"\n",
    "        response = self.llm.invoke(prompt)\n",
    "        decision = str(response)\n",
    "        print(f\"Agent {self.unique_id} made decision: {decision}\")\n",
    "        return decision\n",
    "\n",
    "    # def step(self):\n",
    "    #     context = f\"Agent {self.unique_id} is deciding what to do next.\"\n",
    "    #     decision = self.make_decision(context)\n",
    "    #     print(f\"Agent {self.unique_id} made decision: {decision}\")\n",
    "\n",
    "# Model class\n",
    "class LLMModel(Model):\n",
    "    def __init__(self, width, height, n):\n",
    "        super().__init__()\n",
    "        self.num_agents = n\n",
    "        self.grid = MultiGrid(width, height, True)\n",
    "\n",
    "        # Create agents\n",
    "        agents = LLMAgent.create_agents(model=self, n=n)\n",
    "        x = self.rng.integers(0, self.grid.width, size=(n,))\n",
    "        y = self.rng.integers(0, self.grid.height, size=(n,))\n",
    "        for a, i, j in zip(agents, x, y):\n",
    "            # Add the agent to a random grid cell\n",
    "            self.grid.place_agent(a, (i, j))\n",
    "\n",
    "        # Data collector for tracking decision-making\n",
    "        self.datacollector = DataCollector(\n",
    "            agent_reporters={\"Decision\": lambda a: a.make_decision(f\"Agent {a.unique_id} is deciding what to do next.\")}\n",
    "        )\n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        # self.datacollector.collect(self)\n",
    "        context = \"\"\"\n",
    "You are stuck on an island, you have 3 choices:\n",
    "1) Search for fruits\n",
    "2) Search for material for shelter\n",
    "3) Look around the island for the closest ship to contact\n",
    "Which option would you pick (1,2,3) ?\n",
    "\"\"\"\n",
    "        self.agents.shuffle_do(\"make_decision\", context)\n",
    "\n",
    "# Run the model\n",
    "def run_model():\n",
    "    model = LLMModel(10, 10, 5)\n",
    "    for i in range(10):\n",
    "        print(f\"Step {i+1}\")\n",
    "        model.step()\n",
    "    # agent_data = model.datacollector.get_agent_vars_dataframe()\n",
    "    # print(agent_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "New Banana stock price: 14.200119951081454\n",
      "Step 2\n",
      "New Banana stock price: 12.56414184757466\n",
      "Step 3\n",
      "New Banana stock price: 11.997866323777167\n",
      "Step 4\n",
      "New Banana stock price: 12.22256034927011\n",
      "Step 5\n",
      "New Banana stock price: 14.416503974138202\n",
      "Step 6\n",
      "New Banana stock price: 15.712069513860191\n",
      "Step 7\n",
      "New Banana stock price: 18.628157126187823\n",
      "Step 8\n",
      "New Banana stock price: 21.81279800792835\n",
      "Step 9\n",
      "New Banana stock price: 19.03577353538308\n",
      "Step 10\n",
      "New Banana stock price: 22.407796106356606\n",
      "Step 11\n",
      "New Banana stock price: 21.980420697059436\n",
      "Step 12\n",
      "New Banana stock price: 24.504624295259458\n",
      "Step 13\n",
      "New Banana stock price: 27.469414831834307\n",
      "Step 14\n",
      "New Banana stock price: 24.265410008708017\n",
      "Step 15\n",
      "New Banana stock price: 24.049817970422012\n",
      "Step 16\n",
      "New Banana stock price: 24.80657642133995\n",
      "Step 17\n",
      "New Banana stock price: 23.058506514798346\n",
      "Step 18\n",
      "New Banana stock price: 21.282473061810496\n",
      "Step 19\n",
      "New Banana stock price: 17.442309866292067\n",
      "Step 20\n",
      "New Banana stock price: 15.863375561148708\n",
      "Step 21\n",
      "New Banana stock price: 13.524137468901507\n",
      "Step 22\n",
      "New Banana stock price: 14.87700395369857\n",
      "Step 23\n",
      "New Banana stock price: 13.003731458671538\n",
      "Step 24\n",
      "New Banana stock price: 11.765927287156131\n",
      "Step 25\n",
      "New Banana stock price: 12.094394727392839\n",
      "Step 26\n",
      "New Banana stock price: 10.910138170426045\n",
      "Step 27\n",
      "New Banana stock price: 12.531599958255459\n",
      "Step 28\n",
      "New Banana stock price: 14.783863336820144\n",
      "Step 29\n",
      "New Banana stock price: 17.271746851438902\n",
      "Step 30\n",
      "New Banana stock price: 18.086870974337796\n",
      "Step 31\n",
      "New Banana stock price: 15.48546450259968\n",
      "Step 32\n",
      "New Banana stock price: 15.561326503829406\n",
      "Step 33\n",
      "New Banana stock price: 18.694118924706476\n",
      "Step 34\n",
      "New Banana stock price: 17.970784748028073\n",
      "Step 35\n",
      "New Banana stock price: 15.026952004360277\n",
      "Step 36\n",
      "New Banana stock price: 16.939379587415075\n",
      "Step 37\n",
      "New Banana stock price: 14.00766309518688\n",
      "Step 38\n",
      "New Banana stock price: 13.804920709788748\n",
      "Step 39\n",
      "New Banana stock price: 10.91561961032089\n",
      "Step 40\n",
      "New Banana stock price: 8.422463182598374\n",
      "Step 41\n",
      "New Banana stock price: 10.38332291099998\n",
      "Step 42\n",
      "New Banana stock price: 9.078307988217663\n",
      "Step 43\n",
      "New Banana stock price: 10.442980122825105\n",
      "Step 44\n",
      "New Banana stock price: 7.706584633485117\n",
      "Step 45\n",
      "New Banana stock price: 10.024772036004034\n",
      "Step 46\n",
      "New Banana stock price: 12.164437973962148\n",
      "Step 47\n",
      "New Banana stock price: 9.196210310274456\n",
      "Step 48\n",
      "New Banana stock price: 9.396840444598244\n",
      "Step 49\n",
      "New Banana stock price: 5.136401717660654\n",
      "Step 50\n",
      "New Banana stock price: 6.48479837214372\n",
      "Agent 1\n",
      "Personality: Risk-Averse\n",
      "Stocks: 6\n",
      "Money: 17.253164546725234 \n",
      "Portfolio value: 56.161954779587546\n",
      "              \n",
      "Agent 2\n",
      "Personality: Cautious\n",
      "Stocks: 4\n",
      "Money: 59.55572598927251 \n",
      "Portfolio value: 85.49491947784739\n",
      "              \n",
      "Agent 3\n",
      "Personality: Pessimistic\n",
      "Stocks: 0\n",
      "Money: 79.61602253946174 \n",
      "Portfolio value: 79.61602253946174\n",
      "              \n",
      "Agent 4\n",
      "Personality: Cautious\n",
      "Stocks: 0\n",
      "Money: 86.69002796222063 \n",
      "Portfolio value: 86.69002796222063\n",
      "              \n",
      "Agent 5\n",
      "Personality: Aggressive\n",
      "Stocks: 3\n",
      "Money: 106.46666058687211 \n",
      "Portfolio value: 125.92105570330327\n",
      "              \n",
      "Agent 6\n",
      "Personality: Aggressive\n",
      "Stocks: 6\n",
      "Money: 115.715783023066 \n",
      "Portfolio value: 154.6245732559283\n",
      "              \n",
      "Agent 7\n",
      "Personality: Risk-Averse\n",
      "Stocks: 7\n",
      "Money: 16.139509193159235 \n",
      "Portfolio value: 61.53309779816527\n",
      "              \n",
      "Agent 8\n",
      "Personality: Cautious\n",
      "Stocks: 7\n",
      "Money: 4.58002479092972 \n",
      "Portfolio value: 49.97361339593576\n",
      "              \n",
      "Agent 9\n",
      "Personality: Aggressive\n",
      "Stocks: 6\n",
      "Money: 125.5166725553083 \n",
      "Portfolio value: 164.42546278817062\n",
      "              \n",
      "Agent 10\n",
      "Personality: Optimistic\n",
      "Stocks: 5\n",
      "Money: 56.168677874739494 \n",
      "Portfolio value: 88.59266973545809\n",
      "              \n",
      "Agent 11\n",
      "Personality: Optimistic\n",
      "Stocks: 7\n",
      "Money: 4.8470888499498805 \n",
      "Portfolio value: 50.240677454955915\n",
      "              \n",
      "Agent 12\n",
      "Personality: Aggressive\n",
      "Stocks: 6\n",
      "Money: 148.68570605838124 \n",
      "Portfolio value: 187.59449629124356\n",
      "              \n",
      "Agent 13\n",
      "Personality: Cautious\n",
      "Stocks: 6\n",
      "Money: 38.73470181377987 \n",
      "Portfolio value: 77.6434920466422\n",
      "              \n",
      "Agent 14\n",
      "Personality: Aggressive\n",
      "Stocks: 13\n",
      "Money: 21.558833091776485 \n",
      "Portfolio value: 105.86121192964484\n",
      "              \n",
      "Agent 15\n",
      "Personality: Optimistic\n",
      "Stocks: 8\n",
      "Money: 0.9412876899207792 \n",
      "Portfolio value: 52.81967466707054\n",
      "              \n",
      "Agent 16\n",
      "Personality: Pessimistic\n",
      "Stocks: 0\n",
      "Money: 97.23560265585961 \n",
      "Portfolio value: 97.23560265585961\n",
      "              \n",
      "Agent 17\n",
      "Personality: Risk-Averse\n",
      "Stocks: 4\n",
      "Money: 5.579086391697874 \n",
      "Portfolio value: 31.518279880272754\n",
      "              \n",
      "Agent 18\n",
      "Personality: Risk-Averse\n",
      "Stocks: 8\n",
      "Money: 5.2345205162625374 \n",
      "Portfolio value: 57.112907493412294\n",
      "              \n",
      "Agent 19\n",
      "Personality: Pessimistic\n",
      "Stocks: 0\n",
      "Money: 90.73281146818175 \n",
      "Portfolio value: 90.73281146818175\n",
      "              \n",
      "Agent 20\n",
      "Personality: Risk-Averse\n",
      "Stocks: 8\n",
      "Money: 0.894040293092889 \n",
      "Portfolio value: 52.772427270242645\n",
      "              \n"
     ]
    }
   ],
   "source": [
    "from mesa import Agent, Model\n",
    "import random\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\", num_predict=1)\n",
    "\n",
    "# Agent class with Personality\n",
    "class LLMAgent(Agent):\n",
    "    def __init__(self, unique_id, model, personality):\n",
    "        # Correct initialization of Agent, with the model being passed as the first argument.\n",
    "        super().__init__(model)  # Pass unique_id first and then model to the Agent base class\n",
    "        self.llm = llm  # Access the LLM instance\n",
    "        self.personality = personality  # Personality affects decision-making\n",
    "        self.stock_held = 3  # Start with no stock holdings\n",
    "        self.money_held = 70\n",
    "\n",
    "    def make_decision(self, context):\n",
    "        context = context.invoke({\"amount\" :self.stock_held, \"personality\": self.personality, \"money\": self.money_held})\n",
    "        # print(context)\n",
    "        response = self.llm.invoke(context)\n",
    "        decision = str(response)\n",
    "        # print(f\"Agent {self.unique_id} made decision: {decision}\")\n",
    "        return decision\n",
    "\n",
    "    def buy_stock(self, amount, banana_price):\n",
    "        if self.money_held >= banana_price*amount:\n",
    "            self.stock_held += amount\n",
    "            self.money_held -= banana_price*amount\n",
    "        #     print(f\"Agent {self.unique_id} bought {amount} of Banana stock.\")\n",
    "        # else:\n",
    "        #     print(f\"Agent {self.unique_id} could not buy {amount} of Banana stock.\")\n",
    "        \n",
    "\n",
    "    def sell_stock(self, amount, banana_price):\n",
    "        if self.stock_held >= amount:\n",
    "            self.stock_held -= amount\n",
    "            self.money_held += banana_price*amount\n",
    "        #     print(f\"Agent {self.unique_id} sold {amount} of Banana stock.\")\n",
    "        # else:\n",
    "        #     print(f\"Agent {self.unique_id} tried to sell more than they own.\")\n",
    "\n",
    "    def hold_stock(self):\n",
    "        # print(f\"Agent {self.unique_id} decided to hold their Banana stock.\")\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def status(self, banana_price):\n",
    "        print(f\"\"\"Agent {self.unique_id}\n",
    "Personality: {self.personality}\n",
    "Stocks: {self.stock_held}\n",
    "Money: {self.money_held} \n",
    "Portfolio value: {self.money_held+self.stock_held*banana_price}\n",
    "              \"\"\")\n",
    "\n",
    "\n",
    "# Model class with Stock Pricing\n",
    "class LLMModel(Model):\n",
    "    def __init__(self, width, height, n, initial_prices=[9.5, 9.8, 10, 10.4, 10.1]):\n",
    "        super().__init__()\n",
    "        self.num_agents = n\n",
    "        self.grid = MultiGrid(width, height, True)\n",
    "        self.banana_price = initial_prices  # Initial price of the \"banana\" stock\n",
    "        self.buy_count = 0  # Track the number of buys\n",
    "        self.sell_count = 0  # Track the number of sells\n",
    "\n",
    "        # Create agents with different personalities\n",
    "        personalities = [\"Aggressive\", \"Cautious\", \"Risk-Averse\", \"Optimistic\", \"Pessimistic\"]\n",
    "        agents = [LLMAgent(i, self, random.choice(personalities)) for i in range(self.num_agents)]\n",
    "        x = self.rng.integers(0, self.grid.width, size=(n,))\n",
    "        y = self.rng.integers(0, self.grid.height, size=(n,))\n",
    "        \n",
    "        for a, i, j in zip(agents, x, y):\n",
    "            # Add the agent to a random grid cell\n",
    "            self.grid.place_agent(a, (i, j))\n",
    "\n",
    "        # Data collector for tracking decision-making\n",
    "        self.datacollector = DataCollector(\n",
    "            agent_reporters={\"Decision\": lambda a: a.make_decision(f\"Agent {a.unique_id} is deciding what to do next.\")},\n",
    "            model_reporters={\"BananaPrice\": \"banana_price\"}\n",
    "        )\n",
    "\n",
    "    def calculate_stock_price(self):\n",
    "        # Simple supply-demand model for stock price\n",
    "        price_change = (self.buy_count - self.sell_count) * 0.1  # Small price fluctuation based on buy/sell activity\n",
    "        new_price = self.banana_price[-1] + price_change + random.uniform(-3.0, 3.0)\n",
    "        self.banana_price.append(max(1, new_price))  # Ensure the price doesn't go below 1\n",
    "        print(f\"New Banana stock price: {self.banana_price[-1]}\")\n",
    "\n",
    "    def step(self):\n",
    "        self.buy_count = 0\n",
    "        self.sell_count = 0\n",
    "        \n",
    "        context = \"\"\"\n",
    "The Banana pricing in the past has been: \"\"\" + str(self.banana_price[:-1]) + \"\"\"\"\n",
    "The current price of Banana stock is $\"\"\" + str(self.banana_price[-1]) + \"\"\"\"\n",
    "You have the following options:\n",
    "1) Buy 1 Banana stock.\n",
    "2) Buy 3 Banana stock.\n",
    "3) Buy 5 Banana stock.\n",
    "4) Sell 1 Banana stock.\n",
    "5) Sell 3 Banana stock.\n",
    "6) Sell 5 Banana stock.\n",
    "7) Hold your position.\n",
    "\n",
    "Make your decision. Be mindful of your personality and the current banana pricing. Start your response with the number of the option chosen. You currently hold {amount} banana stocks and you have ${money}.\n",
    "Response no.: \n",
    "\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            (\"system\", \"You are a stock trader who is trading banana stock. Your personality type is {personality}\"),\n",
    "            (\"human\", context)\n",
    "        ]\n",
    "\n",
    "        prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "        # Agents decide on their actions\n",
    "        for agent in self.agents:\n",
    "            decision = agent.make_decision(prompt_template)\n",
    "            if \"1\" in decision.lower():\n",
    "                agent.buy_stock(1, self.banana_price[-1])\n",
    "                self.buy_count += 1\n",
    "            elif \"2\" in decision.lower():\n",
    "                agent.buy_stock(3, self.banana_price[-1])\n",
    "                self.buy_count += 3\n",
    "            elif \"3\" in decision.lower():\n",
    "                agent.buy_stock(5, self.banana_price[-1])\n",
    "                self.buy_count += 5\n",
    "            elif \"4\" in decision.lower():\n",
    "                agent.sell_stock(1, self.banana_price[-1])\n",
    "                self.sell_count += 1\n",
    "            elif \"5\" in decision.lower():\n",
    "                agent.sell_stock(3, self.banana_price[-1])\n",
    "                self.sell_count += 3\n",
    "            elif \"6\" in decision.lower():\n",
    "                agent.sell_stock(5, self.banana_price[-1])\n",
    "                self.sell_count += 5\n",
    "            else:\n",
    "                agent.hold_stock()\n",
    "\n",
    "        # Update the stock price after all actions\n",
    "        self.calculate_stock_price()\n",
    "        # self.datacollector.collect(self)\n",
    "\n",
    "    def status(self):\n",
    "\n",
    "        for agent in self.agents:\n",
    "            agent.status(self.banana_price[-1])\n",
    "\n",
    "# Run the model\n",
    "def run_model():\n",
    "    model = LLMModel(10, 10, 20)\n",
    "    for i in range(50):\n",
    "        print(f\"Step {i+1}\")\n",
    "        model.step()\n",
    "    model.status()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "New Banana stock price: 14.015498366760788\n",
      "Step 2\n",
      "New Banana stock price: 14.054284774702072\n",
      "Step 3\n",
      "New Banana stock price: 16.274461440462634\n",
      "Step 4\n",
      "New Banana stock price: 19.313909785507548\n",
      "Step 5\n",
      "New Banana stock price: 20.48800136873774\n",
      "Step 6\n",
      "New Banana stock price: 22.094819789446888\n",
      "Step 7\n",
      "New Banana stock price: 25.082399311186272\n",
      "Step 8\n",
      "New Banana stock price: 24.634612765317186\n",
      "Step 9\n",
      "New Banana stock price: 23.995354123688074\n",
      "Step 10\n",
      "New Banana stock price: 21.526374835289005\n",
      "Step 11\n",
      "New Banana stock price: 21.585746450835458\n",
      "Step 12\n",
      "New Banana stock price: 22.614136748185643\n",
      "Step 13\n",
      "New Banana stock price: 25.375845028976592\n",
      "Step 14\n",
      "New Banana stock price: 25.435604999121445\n",
      "Step 15\n",
      "New Banana stock price: 24.28051225438829\n",
      "Step 16\n",
      "New Banana stock price: 24.64879903619729\n",
      "Step 17\n",
      "New Banana stock price: 25.268269145132777\n",
      "Step 18\n",
      "New Banana stock price: 25.157103559563325\n",
      "Step 19\n",
      "New Banana stock price: 24.13405630738601\n",
      "Step 20\n",
      "New Banana stock price: 26.293081556630277\n",
      "Step 21\n",
      "New Banana stock price: 27.58628165765272\n",
      "Step 22\n",
      "New Banana stock price: 27.351286961964703\n",
      "Step 23\n",
      "New Banana stock price: 30.31522784217019\n",
      "Step 24\n",
      "New Banana stock price: 27.940949348257305\n",
      "Step 25\n",
      "New Banana stock price: 29.643262132892218\n",
      "Step 26\n",
      "New Banana stock price: 29.323623642377246\n",
      "Step 27\n",
      "New Banana stock price: 26.403394795811355\n",
      "Step 28\n",
      "New Banana stock price: 28.14565319654183\n",
      "Step 29\n",
      "New Banana stock price: 30.119003635840436\n",
      "Step 30\n",
      "New Banana stock price: 27.482331634988697\n",
      "Step 31\n",
      "New Banana stock price: 29.829595244281002\n",
      "Step 32\n",
      "New Banana stock price: 32.07220282793823\n",
      "Step 33\n",
      "New Banana stock price: 34.39829211098436\n",
      "Step 34\n",
      "New Banana stock price: 32.72011541143225\n",
      "Step 35\n",
      "New Banana stock price: 32.67708156583405\n",
      "Step 36\n",
      "New Banana stock price: 35.980403686498036\n",
      "Step 37\n",
      "New Banana stock price: 36.19952380186537\n",
      "Step 38\n",
      "New Banana stock price: 35.102218890959904\n",
      "Step 39\n",
      "New Banana stock price: 35.396746421288746\n",
      "Step 40\n",
      "New Banana stock price: 34.14661613419131\n",
      "Agent 1\n",
      "Personality: Cautious\n",
      "Stocks: 6\n",
      "Money: 20.94096132758802 \n",
      "Portfolio value: 225.8206581327359\n",
      "              \n",
      "Agent 2\n",
      "Personality: Optimistic\n",
      "Stocks: 6\n",
      "Money: 18.637996124226014 \n",
      "Portfolio value: 223.5176929293739\n",
      "              \n",
      "Agent 3\n",
      "Personality: Risk-Averse\n",
      "Stocks: 1\n",
      "Money: 159.3137412996995 \n",
      "Portfolio value: 193.4603574338908\n",
      "              \n",
      "Agent 4\n",
      "Personality: Risk-Averse\n",
      "Stocks: 7\n",
      "Money: 10.064971182015476 \n",
      "Portfolio value: 249.09128412135468\n",
      "              \n",
      "Agent 5\n",
      "Personality: Aggressive\n",
      "Stocks: 0\n",
      "Money: 177.12905105026357 \n",
      "Portfolio value: 177.12905105026357\n",
      "              \n",
      "Agent 6\n",
      "Personality: Cautious\n",
      "Stocks: 0\n",
      "Money: 224.5492200745722 \n",
      "Portfolio value: 224.5492200745722\n",
      "              \n",
      "Agent 7\n",
      "Personality: Aggressive\n",
      "Stocks: 5\n",
      "Money: 62.01504649739735 \n",
      "Portfolio value: 232.7481271683539\n",
      "              \n",
      "Agent 8\n",
      "Personality: Cautious\n",
      "Stocks: 4\n",
      "Money: 114.60335758145061 \n",
      "Portfolio value: 251.18982211821586\n",
      "              \n",
      "Agent 9\n",
      "Personality: Risk-Averse\n",
      "Stocks: 6\n",
      "Money: 11.26384121412395 \n",
      "Portfolio value: 216.14353801927183\n",
      "              \n",
      "Agent 10\n",
      "Personality: Optimistic\n",
      "Stocks: 6\n",
      "Money: 53.58917384021499 \n",
      "Portfolio value: 258.46887064536287\n",
      "              \n",
      "Agent 11\n",
      "Personality: Risk-Averse\n",
      "Stocks: 6\n",
      "Money: 55.28481789434618 \n",
      "Portfolio value: 260.1645146994941\n",
      "              \n",
      "Agent 12\n",
      "Personality: Optimistic\n",
      "Stocks: 7\n",
      "Money: 14.38166383484431 \n",
      "Portfolio value: 253.4079767741835\n",
      "              \n",
      "Agent 13\n",
      "Personality: Aggressive\n",
      "Stocks: 1\n",
      "Money: 131.31615092738912 \n",
      "Portfolio value: 165.46276706158042\n",
      "              \n",
      "Agent 14\n",
      "Personality: Cautious\n",
      "Stocks: 6\n",
      "Money: 25.363822219849354 \n",
      "Portfolio value: 230.24351902499723\n",
      "              \n",
      "Agent 15\n",
      "Personality: Risk-Averse\n",
      "Stocks: 5\n",
      "Money: 85.66772337695895 \n",
      "Portfolio value: 256.40080404791547\n",
      "              \n",
      "Agent 16\n",
      "Personality: Optimistic\n",
      "Stocks: 7\n",
      "Money: 23.813716477942727 \n",
      "Portfolio value: 262.8400294172819\n",
      "              \n",
      "Agent 17\n",
      "Personality: Cautious\n",
      "Stocks: 6\n",
      "Money: 21.43827789653747 \n",
      "Portfolio value: 226.31797470168536\n",
      "              \n",
      "Agent 18\n",
      "Personality: Pessimistic\n",
      "Stocks: 1\n",
      "Money: 76.54490896434467 \n",
      "Portfolio value: 110.69152509853598\n",
      "              \n",
      "Agent 19\n",
      "Personality: Risk-Averse\n",
      "Stocks: 1\n",
      "Money: 213.74522159454628 \n",
      "Portfolio value: 247.89183772873758\n",
      "              \n",
      "Agent 20\n",
      "Personality: Aggressive\n",
      "Stocks: 1\n",
      "Money: 165.9992739515322 \n",
      "Portfolio value: 200.1458900857235\n",
      "              \n"
     ]
    }
   ],
   "source": [
    "from mesa import Agent, Model\n",
    "import random\n",
    "from mesa.space import MultiGrid\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\", num_predict=1)\n",
    "\n",
    "# Agent class with Personality\n",
    "class LLMAgent(Agent):\n",
    "    def __init__(self, unique_id, model, personality):\n",
    "        # Correct initialization of Agent, with the model being passed as the first argument.\n",
    "        super().__init__(model)  # Pass unique_id first and then model to the Agent base class\n",
    "        self.llm = llm  # Access the LLM instance\n",
    "        self.personality = personality  # Personality affects decision-making\n",
    "        self.stock_held = 3  # Start with no stock holdings\n",
    "        self.money_held = 70\n",
    "\n",
    "    def make_decision(self, context):\n",
    "        context = context.invoke({\"amount\" :self.stock_held, \"personality\": self.personality, \"money\": self.money_held})\n",
    "        response = self.llm.invoke(context)\n",
    "        decision = str(response)\n",
    "        return decision\n",
    "\n",
    "    def buy_stock(self, amount, banana_price):\n",
    "        if self.money_held >= banana_price*amount:\n",
    "            self.stock_held += amount\n",
    "            self.money_held -= banana_price*amount\n",
    "            print(f\"Agent {self.unique_id} bought {amount} of Banana stock.\")\n",
    "        else:\n",
    "            print(f\"Agent {self.unique_id} could not buy {amount} of Banana stock.\")\n",
    "        \n",
    "\n",
    "    def sell_stock(self, amount, banana_price):\n",
    "        if self.stock_held >= amount:\n",
    "            self.stock_held -= amount\n",
    "            self.money_held += banana_price*amount\n",
    "            print(f\"Agent {self.unique_id} sold {amount} of Banana stock.\")\n",
    "        else:\n",
    "            print(f\"Agent {self.unique_id} tried to sell more than they own.\")\n",
    "\n",
    "    def hold_stock(self):\n",
    "        print(f\"Agent {self.unique_id} decided to hold their Banana stock.\")\n",
    "\n",
    "    \n",
    "    def status(self, banana_price):\n",
    "        print(f\"\"\"Agent {self.unique_id}\n",
    "Personality: {self.personality}\n",
    "Stocks: {self.stock_held}\n",
    "Money: {self.money_held} \n",
    "Portfolio value: {self.money_held+self.stock_held*banana_price}\n",
    "              \"\"\")\n",
    "\n",
    "\n",
    "# Model class with Stock Pricing\n",
    "class LLMModel(Model):\n",
    "    def __init__(self, width, height, n, initial_prices=[9.5, 9.8, 10, 10.4, 10.1]):\n",
    "        super().__init__()\n",
    "        self.num_agents = n\n",
    "        self.grid = MultiGrid(width, height, True)\n",
    "        self.banana_price = initial_prices  # Initial price of the \"banana\" stock\n",
    "        self.buy_count = 0  # Track the number of buys\n",
    "        self.sell_count = 0  # Track the number of sells\n",
    "\n",
    "        # Create agents with different personalities\n",
    "        personalities = [\"Aggressive\", \"Cautious\", \"Risk-Averse\", \"Optimistic\", \"Pessimistic\"]\n",
    "        agents = [LLMAgent(i, self, random.choice(personalities)) for i in range(self.num_agents)]\n",
    "        x = self.rng.integers(0, self.grid.width, size=(n,))\n",
    "        y = self.rng.integers(0, self.grid.height, size=(n,))\n",
    "        \n",
    "        for a, i, j in zip(agents, x, y):\n",
    "            # Add the agent to a random grid cell\n",
    "            self.grid.place_agent(a, (i, j))\n",
    "\n",
    "    def calculate_stock_price(self):\n",
    "        # Simple supply-demand model for stock price\n",
    "        price_change = (self.buy_count - self.sell_count) * 0.1  # Small price fluctuation based on buy/sell activity\n",
    "        new_price = self.banana_price[-1] + price_change + random.uniform(-3.0, 3.0)\n",
    "        self.banana_price.append(max(1, new_price))  # Ensure the price doesn't go below 1\n",
    "        print(f\"New Banana stock price: {self.banana_price[-1]}\")\n",
    "\n",
    "    def step(self):\n",
    "        self.buy_count = 0\n",
    "        self.sell_count = 0\n",
    "        \n",
    "        context = \"\"\"\n",
    "The Banana pricing in the past has been: \"\"\" + str(self.banana_price[:-1]) + \"\"\"\"\n",
    "The current price of Banana stock is $\"\"\" + str(self.banana_price[-1]) + \"\"\"\"\n",
    "You have the following options:\n",
    "1) Buy 1 Banana stock.\n",
    "2) Buy 3 Banana stock.\n",
    "3) Buy 5 Banana stock.\n",
    "4) Sell 1 Banana stock.\n",
    "5) Sell 3 Banana stock.\n",
    "6) Sell 5 Banana stock.\n",
    "7) Hold your position.\n",
    "\n",
    "Make your decision. Be mindful of your personality and the current banana pricing. Start your response with the number of the option chosen. You currently hold {amount} banana stocks and you have ${money}.\n",
    "Response no.: \n",
    "\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            (\"system\", \"You are a stock trader who is trading banana stock. Your personality type is {personality}\"),\n",
    "            (\"human\", context)\n",
    "        ]\n",
    "\n",
    "        prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "        # Agents decide on their actions\n",
    "        for agent in self.agents:\n",
    "            decision = agent.make_decision(prompt_template)\n",
    "            if \"1\" in decision.lower():\n",
    "                agent.buy_stock(1, self.banana_price[-1])\n",
    "                self.buy_count += 1\n",
    "            elif \"2\" in decision.lower():\n",
    "                agent.buy_stock(3, self.banana_price[-1])\n",
    "                self.buy_count += 3\n",
    "            elif \"3\" in decision.lower():\n",
    "                agent.buy_stock(5, self.banana_price[-1])\n",
    "                self.buy_count += 5\n",
    "            elif \"4\" in decision.lower():\n",
    "                agent.sell_stock(1, self.banana_price[-1])\n",
    "                self.sell_count += 1\n",
    "            elif \"5\" in decision.lower():\n",
    "                agent.sell_stock(3, self.banana_price[-1])\n",
    "                self.sell_count += 3\n",
    "            elif \"6\" in decision.lower():\n",
    "                agent.sell_stock(5, self.banana_price[-1])\n",
    "                self.sell_count += 5\n",
    "            else:\n",
    "                agent.hold_stock()\n",
    "\n",
    "        # Update the stock price after all actions\n",
    "        self.calculate_stock_price()\n",
    "\n",
    "    def status(self):\n",
    "\n",
    "        for agent in self.agents:\n",
    "            agent.status(self.banana_price[-1])\n",
    "\n",
    "# Run the model\n",
    "def run_model():\n",
    "    model = LLMModel(10, 10, 20)\n",
    "    for i in range(40):\n",
    "        print(f\"Step {i+1}\")\n",
    "        model.step()\n",
    "    model.status()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Agent 1 decided to hold their Banana stock.\n",
      "Agent 2 bought 1 of Banana stock.\n",
      "Agent 3 decided to hold their Banana stock.\n",
      "Agent 4 sold 1 of Banana stock.\n",
      "Agent 5 sold 1 of Banana stock.\n",
      "Agent 6 bought 1 of Banana stock.\n",
      "Agent 7 bought 3 of Banana stock.\n",
      "Agent 8 bought 1 of Banana stock.\n",
      "Agent 9 sold 1 of Banana stock.\n",
      "Agent 10 sold 1 of Banana stock.\n",
      "Agent 11 bought 1 of Banana stock.\n",
      "Agent 12 sold 1 of Banana stock.\n",
      "Agent 13 bought 3 of Banana stock.\n",
      "Agent 14 sold 1 of Banana stock.\n",
      "Agent 15 bought 1 of Banana stock.\n",
      "Agent 16 bought 1 of Banana stock.\n",
      "Agent 17 bought 1 of Banana stock.\n",
      "Agent 18 bought 1 of Banana stock.\n",
      "Agent 19 bought 1 of Banana stock.\n",
      "Agent 20 bought 1 of Banana stock.\n",
      "New Banana stock price: 10.870564029960814\n",
      "Step 2\n",
      "Agent 1 sold 1 of Banana stock.\n",
      "Agent 2 bought 1 of Banana stock.\n",
      "Agent 3 sold 1 of Banana stock.\n",
      "Agent 4 decided to hold their Banana stock.\n",
      "Agent 5 sold 1 of Banana stock.\n",
      "Agent 6 bought 5 of Banana stock.\n",
      "Agent 7 decided to hold their Banana stock.\n",
      "Agent 8 bought 5 of Banana stock.\n",
      "Agent 9 sold 1 of Banana stock.\n",
      "Agent 10 decided to hold their Banana stock.\n",
      "Agent 11 bought 5 of Banana stock.\n",
      "Agent 12 sold 1 of Banana stock.\n",
      "Agent 13 sold 1 of Banana stock.\n",
      "Agent 14 sold 1 of Banana stock.\n",
      "Agent 15 bought 1 of Banana stock.\n",
      "Agent 16 bought 1 of Banana stock.\n",
      "Agent 17 bought 1 of Banana stock.\n",
      "Agent 18 bought 1 of Banana stock.\n",
      "Agent 19 bought 1 of Banana stock.\n",
      "Agent 20 bought 1 of Banana stock.\n",
      "New Banana stock price: 9.53153657738601\n",
      "Step 3\n",
      "Agent 1 sold 1 of Banana stock.\n",
      "Agent 2 decided to hold their Banana stock.\n",
      "Agent 3 sold 1 of Banana stock.\n",
      "Agent 4 sold 1 of Banana stock.\n",
      "Agent 5 sold 1 of Banana stock.\n",
      "Agent 6 could not buy 1 of Banana stock.\n",
      "Agent 7 bought 1 of Banana stock.\n",
      "Agent 8 could not buy 3 of Banana stock.\n",
      "Agent 9 sold 1 of Banana stock.\n",
      "Agent 10 sold 1 of Banana stock.\n",
      "Agent 11 could not buy 1 of Banana stock.\n",
      "Agent 12 tried to sell more than they own.\n",
      "Agent 13 bought 1 of Banana stock.\n",
      "Agent 14 sold 1 of Banana stock.\n",
      "Agent 15 sold 1 of Banana stock.\n",
      "Agent 16 bought 1 of Banana stock.\n",
      "Agent 17 bought 1 of Banana stock.\n",
      "Agent 18 bought 1 of Banana stock.\n",
      "Agent 19 bought 1 of Banana stock.\n",
      "Agent 20 sold 1 of Banana stock.\n",
      "New Banana stock price: 6.8199465813162785\n",
      "Step 4\n",
      "Agent 1 bought 5 of Banana stock.\n",
      "Agent 2 decided to hold their Banana stock.\n",
      "Agent 3 decided to hold their Banana stock.\n",
      "Agent 4 tried to sell more than they own.\n",
      "Agent 5 tried to sell more than they own.\n",
      "Agent 6 could not buy 1 of Banana stock.\n",
      "Agent 7 sold 1 of Banana stock.\n",
      "Agent 8 could not buy 1 of Banana stock.\n",
      "Agent 9 decided to hold their Banana stock.\n",
      "Agent 10 sold 1 of Banana stock.\n",
      "Agent 11 could not buy 1 of Banana stock.\n",
      "Agent 12 bought 5 of Banana stock.\n",
      "Agent 13 bought 1 of Banana stock.\n",
      "Agent 14 bought 5 of Banana stock.\n",
      "Agent 15 decided to hold their Banana stock.\n",
      "Agent 16 bought 1 of Banana stock.\n",
      "Agent 17 bought 1 of Banana stock.\n",
      "Agent 18 bought 1 of Banana stock.\n",
      "Agent 19 bought 1 of Banana stock.\n",
      "Agent 20 bought 5 of Banana stock.\n",
      "New Banana stock price: 5.932439852934202\n",
      "Step 5\n",
      "Agent 1 decided to hold their Banana stock.\n",
      "Agent 2 bought 1 of Banana stock.\n",
      "Agent 3 decided to hold their Banana stock.\n",
      "Agent 4 sold 1 of Banana stock.\n",
      "Agent 5 bought 5 of Banana stock.\n",
      "Agent 6 sold 1 of Banana stock.\n",
      "Agent 7 sold 1 of Banana stock.\n",
      "Agent 8 sold 1 of Banana stock.\n",
      "Agent 9 bought 1 of Banana stock.\n",
      "Agent 10 tried to sell more than they own.\n",
      "Agent 11 could not buy 1 of Banana stock.\n",
      "Agent 12 sold 1 of Banana stock.\n",
      "Agent 13 decided to hold their Banana stock.\n",
      "Agent 14 sold 5 of Banana stock.\n",
      "Agent 15 bought 1 of Banana stock.\n",
      "Agent 16 bought 1 of Banana stock.\n",
      "Agent 17 decided to hold their Banana stock.\n",
      "Agent 18 bought 1 of Banana stock.\n",
      "Agent 19 bought 1 of Banana stock.\n",
      "Agent 20 decided to hold their Banana stock.\n",
      "New Banana stock price: 3.085825071670792\n",
      "Step 6\n",
      "Agent 1 decided to hold their Banana stock.\n",
      "Agent 2 sold 1 of Banana stock.\n",
      "Agent 3 sold 1 of Banana stock.\n",
      "Agent 4 tried to sell more than they own.\n",
      "Agent 5 sold 5 of Banana stock.\n",
      "Agent 6 bought 3 of Banana stock.\n",
      "Agent 7 bought 1 of Banana stock.\n",
      "Agent 8 sold 5 of Banana stock.\n",
      "Agent 9 sold 1 of Banana stock.\n",
      "Agent 10 tried to sell more than they own.\n",
      "Agent 11 bought 1 of Banana stock.\n",
      "Agent 12 decided to hold their Banana stock.\n",
      "Agent 13 bought 1 of Banana stock.\n",
      "Agent 14 bought 1 of Banana stock.\n",
      "Agent 15 decided to hold their Banana stock.\n",
      "Agent 16 decided to hold their Banana stock.\n",
      "Agent 17 bought 3 of Banana stock.\n",
      "Agent 18 bought 1 of Banana stock.\n",
      "Agent 19 bought 1 of Banana stock.\n",
      "Agent 20 sold 1 of Banana stock.\n",
      "New Banana stock price: 1.585673370714002\n",
      "Step 7\n",
      "Agent 1 decided to hold their Banana stock.\n",
      "Agent 2 decided to hold their Banana stock.\n",
      "Agent 3 bought 1 of Banana stock.\n",
      "Agent 4 tried to sell more than they own.\n",
      "Agent 5 tried to sell more than they own.\n",
      "Agent 6 bought 1 of Banana stock.\n",
      "Agent 7 sold 1 of Banana stock.\n",
      "Agent 8 decided to hold their Banana stock.\n",
      "Agent 9 decided to hold their Banana stock.\n",
      "Agent 10 tried to sell more than they own.\n",
      "Agent 11 bought 1 of Banana stock.\n",
      "Agent 12 bought 1 of Banana stock.\n",
      "Agent 13 bought 1 of Banana stock.\n",
      "Agent 14 sold 1 of Banana stock.\n",
      "Agent 15 sold 1 of Banana stock.\n",
      "Agent 16 bought 1 of Banana stock.\n",
      "Agent 17 bought 3 of Banana stock.\n",
      "Agent 18 sold 1 of Banana stock.\n",
      "Agent 19 bought 1 of Banana stock.\n",
      "Agent 20 decided to hold their Banana stock.\n",
      "New Banana stock price: 1\n",
      "Step 8\n",
      "Agent 1 sold 1 of Banana stock.\n",
      "Agent 2 bought 1 of Banana stock.\n",
      "Agent 3 bought 5 of Banana stock.\n",
      "Agent 4 decided to hold their Banana stock.\n",
      "Agent 5 tried to sell more than they own.\n",
      "Agent 6 decided to hold their Banana stock.\n",
      "Agent 7 decided to hold their Banana stock.\n",
      "Agent 8 bought 3 of Banana stock.\n",
      "Agent 9 decided to hold their Banana stock.\n",
      "Agent 10 tried to sell more than they own.\n",
      "Agent 11 could not buy 1 of Banana stock.\n",
      "Agent 12 sold 1 of Banana stock.\n",
      "Agent 13 decided to hold their Banana stock.\n",
      "Agent 14 tried to sell more than they own.\n",
      "Agent 15 bought 1 of Banana stock.\n",
      "Agent 16 bought 1 of Banana stock.\n",
      "Agent 17 bought 1 of Banana stock.\n",
      "Agent 18 bought 1 of Banana stock.\n",
      "Agent 19 bought 1 of Banana stock.\n",
      "Agent 20 sold 1 of Banana stock.\n",
      "New Banana stock price: 1.3601498509727805\n",
      "Step 9\n",
      "Agent 1 sold 1 of Banana stock.\n",
      "Agent 2 decided to hold their Banana stock.\n",
      "Agent 3 sold 1 of Banana stock.\n",
      "Agent 4 tried to sell more than they own.\n",
      "Agent 5 tried to sell more than they own.\n",
      "Agent 6 could not buy 1 of Banana stock.\n",
      "Agent 7 decided to hold their Banana stock.\n",
      "Agent 8 bought 5 of Banana stock.\n",
      "Agent 9 bought 1 of Banana stock.\n",
      "Agent 10 tried to sell more than they own.\n",
      "Agent 11 could not buy 1 of Banana stock.\n",
      "Agent 12 sold 1 of Banana stock.\n",
      "Agent 13 sold 1 of Banana stock.\n",
      "Agent 14 decided to hold their Banana stock.\n",
      "Agent 15 sold 1 of Banana stock.\n"
     ]
    }
   ],
   "source": [
    "from mesa import Agent, Model\n",
    "import random\n",
    "from mesa.space import MultiGrid\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\", num_predict=1)\n",
    "\n",
    "# Agent class with Personality\n",
    "class LLMAgent(Agent):\n",
    "    def __init__(self, unique_id, model, personality):\n",
    "        # Correct initialization of Agent, with the model being passed as the first argument.\n",
    "        super().__init__(model)  # Pass unique_id first and then model to the Agent base class\n",
    "        self.llm = llm  # Access the LLM instance\n",
    "        self.personality = personality  # Personality affects decision-making\n",
    "        self.stock_held = 3  # Start with no stock holdings\n",
    "        self.money_held = 70\n",
    "\n",
    "    def make_decision(self, context):\n",
    "        context = context.invoke({\"amount\" :self.stock_held, \"personality\": self.personality, \"money\": self.money_held})\n",
    "        response = self.llm.invoke(context)\n",
    "        decision = str(response)\n",
    "        return decision\n",
    "\n",
    "    def buy_stock(self, amount, banana_price):\n",
    "        if self.money_held >= banana_price*amount:\n",
    "            self.stock_held += amount\n",
    "            self.money_held -= banana_price*amount\n",
    "            print(f\"Agent {self.unique_id} bought {amount} of Banana stock.\")\n",
    "        else:\n",
    "            print(f\"Agent {self.unique_id} could not buy {amount} of Banana stock.\")\n",
    "        \n",
    "\n",
    "    def sell_stock(self, amount, banana_price):\n",
    "        if self.stock_held >= amount:\n",
    "            self.stock_held -= amount\n",
    "            self.money_held += banana_price*amount\n",
    "            print(f\"Agent {self.unique_id} sold {amount} of Banana stock.\")\n",
    "        else:\n",
    "            print(f\"Agent {self.unique_id} tried to sell more than they own.\")\n",
    "\n",
    "    def hold_stock(self):\n",
    "        print(f\"Agent {self.unique_id} decided to hold their Banana stock.\")\n",
    "\n",
    "    \n",
    "    def status(self, banana_price):\n",
    "        print(f\"\"\"Agent {self.unique_id}\n",
    "Personality: {self.personality}\n",
    "Stocks: {self.stock_held}\n",
    "Money: {self.money_held} \n",
    "Portfolio value: {self.money_held+self.stock_held*banana_price}\n",
    "              \"\"\")\n",
    "\n",
    "\n",
    "# Model class with Stock Pricing\n",
    "class LLMModel(Model):\n",
    "    def __init__(self, width, height, n, initial_prices=[9.5, 9.8, 10, 10.4, 10.1]):\n",
    "        super().__init__()\n",
    "        self.num_agents = n\n",
    "        self.grid = MultiGrid(width, height, True)\n",
    "        self.banana_price = initial_prices  # Initial price of the \"banana\" stock\n",
    "        self.buy_count = 0  # Track the number of buys\n",
    "        self.sell_count = 0  # Track the number of sells\n",
    "\n",
    "        # Create agents with different personalities\n",
    "        personalities = [\"Aggressive\", \"Cautious\", \"Risk-Averse\", \"Optimistic\", \"Pessimistic\"]\n",
    "        agents = [LLMAgent(i, self, random.choice(personalities)) for i in range(self.num_agents)]\n",
    "        x = self.rng.integers(0, self.grid.width, size=(n,))\n",
    "        y = self.rng.integers(0, self.grid.height, size=(n,))\n",
    "        \n",
    "        for a, i, j in zip(agents, x, y):\n",
    "            # Add the agent to a random grid cell\n",
    "            self.grid.place_agent(a, (i, j))\n",
    "\n",
    "    def calculate_stock_price(self):\n",
    "        # Simple supply-demand model for stock price\n",
    "        price_change = (self.buy_count - self.sell_count) * 0.05  # Small price fluctuation based on buy/sell activity\n",
    "        new_price = self.banana_price[-1] + price_change + random.uniform(-2.0, 2.0)\n",
    "        self.banana_price.append(max(1, new_price))  # Ensure the price doesn't go below 1\n",
    "        print(f\"New Banana stock price: {self.banana_price[-1]}\")\n",
    "\n",
    "    def step(self):\n",
    "        self.buy_count = 0\n",
    "        self.sell_count = 0\n",
    "        \n",
    "        context = \"\"\"\n",
    "The Banana pricing in the past has been: \"\"\" + str(self.banana_price[:-1]) + \"\"\"\"\n",
    "The current price of Banana stock is $\"\"\" + str(self.banana_price[-1]) + \"\"\"\"\n",
    "You have the following options:\n",
    "1) Buy 1 Banana stock.\n",
    "2) Buy 3 Banana stock.\n",
    "3) Buy 5 Banana stock.\n",
    "4) Sell 1 Banana stock.\n",
    "5) Sell 3 Banana stock.\n",
    "6) Sell 5 Banana stock.\n",
    "7) Hold your position.\n",
    "\n",
    "Make your decision. Be mindful of your personality and the current banana pricing. Start your response with the number of the option chosen. You currently hold {amount} banana stocks and you have ${money}.\n",
    "Response no.: \n",
    "\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            (\"system\", \"You are a stock trader who is trading banana stock. Your personality type is {personality}\"),\n",
    "            (\"human\", context)\n",
    "        ]\n",
    "\n",
    "        prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "        # Agents decide on their actions\n",
    "        for agent in self.agents:\n",
    "            decision = agent.make_decision(prompt_template)\n",
    "            if \"1\" in decision.lower():\n",
    "                agent.buy_stock(1, self.banana_price[-1])\n",
    "                self.buy_count += 1\n",
    "            elif \"2\" in decision.lower():\n",
    "                agent.buy_stock(3, self.banana_price[-1])\n",
    "                self.buy_count += 3\n",
    "            elif \"3\" in decision.lower():\n",
    "                agent.buy_stock(5, self.banana_price[-1])\n",
    "                self.buy_count += 5\n",
    "            elif \"4\" in decision.lower():\n",
    "                agent.sell_stock(1, self.banana_price[-1])\n",
    "                self.sell_count += 1\n",
    "            elif \"5\" in decision.lower():\n",
    "                agent.sell_stock(3, self.banana_price[-1])\n",
    "                self.sell_count += 3\n",
    "            elif \"6\" in decision.lower():\n",
    "                agent.sell_stock(5, self.banana_price[-1])\n",
    "                self.sell_count += 5\n",
    "            else:\n",
    "                agent.hold_stock()\n",
    "\n",
    "        # Update the stock price after all actions\n",
    "        self.calculate_stock_price()\n",
    "\n",
    "    def status(self):\n",
    "\n",
    "        for agent in self.agents:\n",
    "            agent.status(self.banana_price[-1])\n",
    "\n",
    "# Run the model\n",
    "def run_model():\n",
    "    model = LLMModel(10, 10, 20)\n",
    "    for i in range(15):\n",
    "        print(f\"Step {i+1}\")\n",
    "        model.step()\n",
    "    model.status()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
