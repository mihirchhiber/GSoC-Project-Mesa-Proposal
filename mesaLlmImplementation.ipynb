{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Agent 4 made decision: Given my goal is to survive and potentially get rescued as soon as possible, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "Finding a ship with a means of communication could be the quickest way to get help and possibly even rescue. Searching for fruits (option 1) might provide sustenance in the short term but wouldn't address my primary goal of getting off the island. Building shelter (option 2) is also important, but it's not as crucial as finding a means of communication to alert others about my situation.\n",
      "\n",
      "By prioritizing option 3, I'm taking a proactive step towards potentially getting rescued sooner rather than later.\n",
      "Agent 3 made decision: A classic survival scenario!\n",
      "\n",
      "Given my goal is to survive and potentially get rescued, I would choose:\n",
      "\n",
      "**Option 3: Look around the island for the closest ship to contact**\n",
      "\n",
      "Why? Well, finding shelter and food are essential, but they don't necessarily guarantee rescue. On the other hand, finding a nearby ship could greatly increase my chances of being spotted by rescuers or even signaling for help.\n",
      "\n",
      "By searching for materials for shelter (Option 2) and fruits (Option 1), I would be addressing immediate needs, but not necessarily taking advantage of an opportunity to get rescued sooner rather than later. With the island's resources at hand, I can create a temporary shelter and gather food, which will sustain me in the short term.\n",
      "\n",
      "However, by searching for the closest ship (Option 3), I'm taking a proactive approach that could lead to a faster rescue or even a chance to signal for help before I exhaust my energy. This option seems like the most strategic choice, as it maximizes my chances of getting off the island sooner rather than later.\n",
      "\n",
      "Of course, this decision assumes there's a ship in sight. If there is no ship nearby, then searching for shelter and food would be my next priority!\n",
      "Agent 5 made decision: Given my goal of surviving and potentially escaping the island, I would choose option 3: \"Look around the island for the closest ship to contact\".\n",
      "\n",
      "While searching for fruits (option 1) might provide immediate sustenance, it's unlikely to solve my long-term survival problem. Similarly, finding material for shelter (option 2) is important for protection, but it won't help me escape the island unless I can signal for rescue.\n",
      "\n",
      "On the other hand, looking around the island for a ship (option 3) increases my chances of being rescued and escaping the island. This option aligns with my primary goal of survival and potentially finding a way off the island.\n",
      "\n",
      "I'll take this opportunity to search for a ship that might be passing by or anchored in the nearby waters.\n",
      "Agent 2 made decision: Given my goal is to survive and potentially escape the island, I would choose:\n",
      "\n",
      "Option 2: Search for material for shelter\n",
      "\n",
      "Having a basic shelter can provide me with protection from the elements, wildlife, and potential hazards on the island. It can also serve as a starting point for other tasks such as finding food and water.\n",
      "\n",
      "While searching for fruits (Option 1) could be a good source of immediate sustenance, it may not address my long-term survival needs. Finding materials for shelter will provide me with a foundation to build upon, potentially creating more opportunities for finding food and other essential resources.\n",
      "\n",
      "Searching for the closest ship (Option 3) is also important, but it's crucial to have a basic shelter in place before venturing out to search for rescue or signaling devices.\n",
      "Agent 1 made decision: Given the context, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "My primary goal is to get rescued or at least establish communication with the outside world. Searching for fruits and building shelter are essential tasks, but they can be done once I have a reliable means of survival and safety.\n",
      "\n",
      "By locating the closest ship, I increase my chances of being spotted by rescue personnel, which would greatly improve my chances of getting off the island safely. This option prioritizes getting help over other immediate needs, as it has the potential to bring me back home or provide aid in the form of medical attention, food, and shelter.\n",
      "\n",
      "While searching for fruits and building shelter are important, I believe that having a reliable means of rescue is the most critical step in ensuring my survival on the island.\n",
      "Step 2\n",
      "Agent 1 made decision: Given my goal is to survive and possibly find a way off the island, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "While searching for fruits (option 1) could provide me with immediate sustenance, it may not address the long-term issue of being stranded on the island. Searching for material for shelter (option 2) is also important, but I'm assuming there's a better way to ensure my safety and well-being in the short term.\n",
      "\n",
      "By looking for the closest ship (option 3), I hope to find rescue or at least get a sense of how far away my potential saviors are. This will allow me to assess the risks and benefits of exploring the island, searching for shelter, and scavenging for food.\n",
      "Agent 5 made decision: Given that I want to survive and potentially be rescued from the island, I would choose:\n",
      "\n",
      "(3) Look around the island for the closest ship to contact\n",
      "\n",
      "This is my top priority because finding a ship or some other means of rescue is crucial for getting off the island safely and in time. While searching for fruits (option 1) can provide me with sustenance, it's not as pressing an issue as finding help.\n",
      "\n",
      "Searching for material for shelter (option 2) is also important for my survival, but I can start building a shelter once I have some basic needs met, such as food and water. Having a reliable means of contact with the outside world takes priority over having a physical structure to protect me from the elements.\n",
      "\n",
      "Therefore, option (3) takes precedence over options (1) and (2).\n",
      "Agent 2 made decision: Given my goal of getting rescued or finding other means of survival and eventually escaping the island, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "Finding food and building shelter are important, but if there's no way to communicate with anyone outside the island, it's unlikely that rescue will come. By searching for a ship, I'm taking proactive steps towards getting rescued and increasing my chances of survival in the long run.\n",
      "Agent 4 made decision: Given the context, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "My primary goal is to survive and potentially get rescued. Finding a ship would be the most effective way to do so, as it would likely have food, water, and medical supplies on board, which are essential for survival. While searching for fruits (option 1) or material for shelter (option 2) could provide some immediate benefits, they are not as crucial to my overall goal of getting rescued.\n",
      "\n",
      "By prioritizing the search for a ship, I would be focusing on the most significant opportunity for rescue and potentially increasing my chances of survival.\n",
      "Agent 3 made decision: Given my goal is to survive and potentially find a way off the island, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "Finding shelter and food are essential, but they can wait until I have a better chance of getting rescued or signaling for help. Right now, the primary objective should be to get in touch with the outside world and potentially receive assistance. Searching for material for shelter (option 2) is important, but it's not as urgent as trying to contact potential rescuers.\n",
      "\n",
      "Searching for fruits (option 1) can provide temporary sustenance, but it's a limited resource that might not sustain me for an extended period. In contrast, finding the closest ship (option 3) increases my chances of getting rescued quickly and efficiently.\n",
      "\n",
      "So, option 3 is my priority choice.\n",
      "Step 3\n",
      "Agent 3 made decision: Given my current situation of being stuck on an island, I would choose option 2: Search for material for shelter.\n",
      "\n",
      "My primary goal is to survive and stay safe until help arrives or I can find a way to escape the island. Having a suitable shelter will provide me with protection from the elements, wildlife, and any potential hazards on the island. This option will give me a better chance of survival in the short term.\n",
      "\n",
      "While searching for fruits (option 1) might be helpful for nutrition, it's not as critical as finding shelter first. And looking around for the closest ship to contact (option 3) is essential, but I should prioritize finding a way to secure my basic needs before venturing out to search for rescue.\n",
      "\n",
      "By choosing option 2, I can start building a foundation for survival and increase my chances of staying safe until help arrives.\n",
      "Agent 5 made decision: Given that my primary goal is to survive and potentially escape the island, I would choose option 3: \"Look around the island for the closest ship to contact\".\n",
      "\n",
      "By searching for a nearby ship, I increase my chances of being rescued or getting help from other means. This approach also allows me to conserve energy and resources by not having to search extensively for food and building materials at this stage.\n",
      "\n",
      "While finding fruits (option 1) could provide immediate sustenance, it's unlikely that they would lead to a rescue or long-term survival. Finding material for shelter (option 2) is important, but I can prioritize that after ensuring my safety through contact with the outside world.\n",
      "\n",
      "Therefore, option 3 seems like the most prudent choice, given my limited resources and primary goal of survival and potential escape.\n",
      "Agent 2 made decision: Considering my goal is to survive and potentially escape the island, I would choose:\n",
      "\n",
      "**Option 2: Search for material for shelter**\n",
      "\n",
      "Having access to basic necessities like food and water are important, but having a safe and secure place to live will be crucial in protecting me from potential dangers on the island. Searching for materials for shelter will allow me to build or create a basic structure that can provide me with protection from the elements, wildlife, and other hazards.\n",
      "\n",
      "While searching for fruits (Option 1) may provide temporary sustenance, it's not a sustainable solution that would address my long-term survival needs. And looking around for a ship (Option 3) is unlikely to yield immediate results, as I'm stranded on an island with no clear connection to the outside world.\n",
      "\n",
      "By prioritizing shelter, I can focus on building a foundation for my survival and potentially increase my chances of being rescued or finding ways to signal for help.\n",
      "Agent 1 made decision: Based on my current situation as being stuck on an island, I would choose option 3: \"Look around the island for the closest ship to contact\".\n",
      "\n",
      "My goal is to escape the island and get rescued or find a way to sustain myself until help arrives. Since contacting someone (e.g., getting rescued) is crucial, I want to prioritize finding the closest ship.\n",
      "\n",
      "Searching for fruits (option 1) might provide me with temporary sustenance, but it won't address my long-term goal of escaping the island.\n",
      "\n",
      "Searching for material for shelter (option 2) is important for survival, but it can wait until after I've found a way to contact someone or get rescued.\n",
      "\n",
      "Looking around the island for the closest ship (option 3) increases my chances of getting in touch with rescue services or finding help. This option prioritizes my goal of escaping and seeking assistance over other immediate needs like food and shelter.\n",
      "\n",
      "So, my decision is: option 3.\n",
      "Agent 4 made decision: Given the context of being stuck on an island and having limited resources, my primary goal is to survive and potentially find a way off the island.\n",
      "\n",
      "Considering this, I would choose option 2: Search for material for shelter.\n",
      "\n",
      "Having a suitable shelter will provide me with protection from the elements, including rain, sun, wind, and potential wildlife threats. This will allow me to conserve energy and focus on other aspects of survival, such as finding food and water.\n",
      "\n",
      "While searching for fruits (option 1) may be essential for sustenance, it's not a guaranteed source of food, and I don't know what kind of fruits are available or safe to eat. Moreover, searching for materials for shelter will also help me find potential building materials, which can potentially aid in finding food sources.\n",
      "\n",
      "Looking around the island for the closest ship (option 3) is a long shot and may not provide immediate results. It's possible that there might not be any ships nearby, or even if I do find one, it may not be seaworthy or equipped to take me back to civilization.\n",
      "\n",
      "Therefore, my priority is to focus on finding shelter first, which will enable me to survive for an extended period and make further decisions about how to proceed.\n",
      "Step 4\n",
      "Agent 5 made decision: Based on my priority to survive and potentially be rescued, I would choose option 3: Look around the island for the closest ship to contact.\n",
      "\n",
      "My goal is not only to survive but also to be found by potential rescuers. Having access to a ship could provide me with food, water, medical supplies, and eventually, rescue.\n",
      "\n",
      "While searching for fruits (option 1) might provide short-term sustenance, it may not address my long-term needs or provide any means of communication. Similarly, searching for material for shelter (option 2) is crucial, but without a way to contact the outside world, I may not be able to receive help in time.\n",
      "\n",
      "By looking around the island for the closest ship (option 3), I increase my chances of being spotted by potential rescuers and receiving assistance as soon as possible. This option aligns with my goal of survival and rescue, making it the most suitable choice.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# agent_data = model.datacollector.get_agent_vars_dataframe()\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# print(agent_data)\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\mesa\\model.py:122\u001b[39m, in \u001b[36mModel._wrapped_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m _mesa_logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcalling model.step for timestep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Call the original user-defined step method\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_user_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mLLMModel.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     52\u001b[39m         \u001b[38;5;66;03m# self.datacollector.collect(self)\u001b[39;00m\n\u001b[32m     53\u001b[39m         context = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[33mYou are stuck on an island, you have 3 choices:\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[33m1) Search for fruits\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m \u001b[33mWhich option would you pick (1,2,3) ?\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshuffle_do\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmake_decision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\mesa\\agent.py:345\u001b[39m, in \u001b[36mAgentSet.shuffle_do\u001b[39m\u001b[34m(self, method, *args, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ref \u001b[38;5;129;01min\u001b[39;00m weakrefs:\n\u001b[32m    344\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (agent := ref()) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m             \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ref \u001b[38;5;129;01min\u001b[39;00m weakrefs:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mLLMAgent.make_decision\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_decision\u001b[39m(\u001b[38;5;28mself\u001b[39m, context):\n\u001b[32m     19\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGiven the context: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, make a decision based on your goals.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     decision = \u001b[38;5;28mstr\u001b[39m(response)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAgent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.unique_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m made decision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:390\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    382\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m     **kwargs: Any,\n\u001b[32m    387\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    388\u001b[39m     config = ensure_config(config)\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    401\u001b[39m         .text\n\u001b[32m    402\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:763\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    756\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    757\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m     **kwargs: Any,\n\u001b[32m    761\u001b[39m ) -> LLMResult:\n\u001b[32m    762\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:966\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    952\u001b[39m     run_managers = [\n\u001b[32m    953\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    954\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m         )\n\u001b[32m    965\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    778\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    779\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    786\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    795\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    796\u001b[39m         )\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    798\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:288\u001b[39m, in \u001b[36mOllamaLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m generations = []\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     generations.append([final_chunk])\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:256\u001b[39m, in \u001b[36mOllamaLLM._stream_with_aggregation\u001b[39m\u001b[34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stream_with_aggregation\u001b[39m(\n\u001b[32m    248\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    249\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    253\u001b[39m     **kwargs: Any,\n\u001b[32m    254\u001b[39m ) -> GenerationChunk:\n\u001b[32m    255\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    262\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:211\u001b[39m, in \u001b[36mOllamaLLM._create_generate_stream\u001b[39m\u001b[34m(self, prompt, stop, **kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_generate_stream\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    207\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    208\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    209\u001b[39m     **kwargs: Any,\n\u001b[32m    210\u001b[39m ) -> Iterator[Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.generate(\n\u001b[32m    212\u001b[39m         **\u001b[38;5;28mself\u001b[39m._generate_params(prompt, stop=stop, **kwargs)\n\u001b[32m    213\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\ollama\\_client.py:170\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    167\u001b[39m   e.response.read()\n\u001b[32m    168\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:929\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m decoder = LineDecoder()\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:916\u001b[39m, in \u001b[36mResponse.iter_text\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    914\u001b[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "# %%\n",
    "import random\n",
    "from mesa import Agent, Model\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "# Initialize LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Agent class\n",
    "class LLMAgent(Agent):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(model)\n",
    "        self.llm = llm  # Access the LLM instance\n",
    "\n",
    "    def make_decision(self, context):\n",
    "        prompt = f\"Given the context: {context}, make a decision based on your goals.\"\n",
    "        response = self.llm.invoke(prompt)\n",
    "        decision = str(response)\n",
    "        print(f\"Agent {self.unique_id} made decision: {decision}\")\n",
    "        return decision\n",
    "\n",
    "    # def step(self):\n",
    "    #     context = f\"Agent {self.unique_id} is deciding what to do next.\"\n",
    "    #     decision = self.make_decision(context)\n",
    "    #     print(f\"Agent {self.unique_id} made decision: {decision}\")\n",
    "\n",
    "# Model class\n",
    "class LLMModel(Model):\n",
    "    def __init__(self, width, height, n):\n",
    "        super().__init__()\n",
    "        self.num_agents = n\n",
    "        self.grid = MultiGrid(width, height, True)\n",
    "\n",
    "        # Create agents\n",
    "        agents = LLMAgent.create_agents(model=self, n=n)\n",
    "        x = self.rng.integers(0, self.grid.width, size=(n,))\n",
    "        y = self.rng.integers(0, self.grid.height, size=(n,))\n",
    "        for a, i, j in zip(agents, x, y):\n",
    "            # Add the agent to a random grid cell\n",
    "            self.grid.place_agent(a, (i, j))\n",
    "\n",
    "        # Data collector for tracking decision-making\n",
    "        self.datacollector = DataCollector(\n",
    "            agent_reporters={\"Decision\": lambda a: a.make_decision(f\"Agent {a.unique_id} is deciding what to do next.\")}\n",
    "        )\n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        # self.datacollector.collect(self)\n",
    "        context = \"\"\"\n",
    "You are stuck on an island, you have 3 choices:\n",
    "1) Search for fruits\n",
    "2) Search for material for shelter\n",
    "3) Look around the island for the closest ship to contact\n",
    "Which option would you pick (1,2,3) ?\n",
    "\"\"\"\n",
    "        self.agents.shuffle_do(\"make_decision\", context)\n",
    "\n",
    "# Run the model\n",
    "def run_model():\n",
    "    model = LLMModel(10, 10, 5)\n",
    "    for i in range(10):\n",
    "        print(f\"Step {i+1}\")\n",
    "        model.step()\n",
    "    # agent_data = model.datacollector.get_agent_vars_dataframe()\n",
    "    # print(agent_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Agent 1 made decision: 1) Sell Banana stock.\n",
      "\n",
      "I'm inclined to sell due to my pessimistic nature, which often clouds my investment decisions. I don't expect the price of Banana stock to drop significantly, but I also don't think it will increase substantially in the near future. By selling now, I'll at least avoid taking on more risk than necessary and potentially be left with a loss that aligns with my expectations of a disappointing outcome.\n",
      "Agent 1 bought 1 of Banana stock.\n",
      "Agent 2 made decision: 1. Sell Banana stock.\n",
      "\n",
      "I'm not optimistic about the future price of Banana stock, considering its current low value of $100. Given my pessimistic nature, I believe the market is likely to fluctuate downwards, and it's better to cash out now rather than risking a potential loss by holding onto the stock. Selling will allow me to cut my losses and move on from this investment.\n",
      "Agent 2 decided to hold their Banana stock.\n",
      "Agent 3 made decision: 1. Sell Banana stock.\n",
      "\n",
      "I'm choosing to sell now because I want to maximize my profits before this trend goes sour. My aggressive nature tells me to capitalize on the current high price and cut losses, rather than holding onto a potentially volatile investment.\n",
      "Agent 3 decided to hold their Banana stock.\n",
      "Agent 4 made decision: 1. Hold my stock.\n",
      "\n",
      "I'm choosing to hold onto my Banana stock due to my risk-averse nature. With the current price being $100, I don't feel confident enough to buy more or sell at this point. The uncertainty of market fluctuations makes me hesitant to make any drastic moves. Holding on and monitoring the situation seems like a safer approach for now.\n",
      "Agent 4 decided to hold their Banana stock.\n",
      "Agent 5 made decision: 1. Hold my stock.\n",
      "\n",
      "I'm choosing to hold onto my Banana stock due to caution, given that the current price is $100. I don't want to make any impulsive decisions without more information about market trends or potential changes in demand. Holding onto my stock allows me to reassess the situation later and consider alternative options if the price drops or rises significantly.\n",
      "Agent 5 decided to hold their Banana stock.\n",
      "New Banana stock price: 100.1\n",
      "Agent 1 made decision: *Sigh* Fine, let's get this over with.\n",
      "\n",
      "As an agent working in the shadows, I've got more problems than solutions. My phone is blowing up with notifications from HQ, and my cover is about to be blown anyway. But, what choice do I have? I'll just play along for now, but mark my words, it won't end well.\n",
      "\n",
      "I glance at my notes and see that our target, the infamous \"Echo-12,\" has been spotted in a high-risk location. My gut tells me this is going to be a disaster waiting to happen. We're talking multiple security measures, advanced surveillance systems... it's like they're begging us to get caught.\n",
      "\n",
      "But, I've got a job to do, and I'm not about to let some pesky little setback like this ruin everything. So, I make the call. We'll go in, gather intel, and get out before things escalate any further.\n",
      "\n",
      "I dial up my team and tell them to gear up. \"Alright, listen up. Our target is Echo-12, location: high-risk zone. Intel suggests multiple security measures, but we've got this one covered. Meet us at the old clock tower at midnight. Come armed to the teeth.\"\n",
      "\n",
      "There's a pause on the other end of the line, and for a moment, I worry that they're not going to show up. But then, I hear the sound of equipment being checked and the murmur of team members confirming their attendance.\n",
      "\n",
      "\"Alright, let's get this over with,\" I mutter to myself. This is going to be a long night...\n",
      "Agent 2 made decision: *Sigh* Another dead-end mission, another failure waiting to happen. Why bother trying anyway? It's not like it's going to make a difference in the grand scheme of things.\n",
      "\n",
      "I glance around our dingy hideout, taking in the same old familiar surroundings that never seem to change. It's always the same story - we're tasked with rescuing some high-ranking official or infiltrating a heavily guarded facility, and it always ends in disaster.\n",
      "\n",
      "My mind starts racing with all the ways this could go wrong. The guards will be too alert, the trap will spring shut before we even get close to our target, or worse, I'll blow my cover and have to make a hasty exit while everyone thinks I'm dead.\n",
      "\n",
      "I rub my temples, feeling the familiar knot of anxiety forming in my stomach. Why do I always fall for these kinds of missions? Why can't anyone trust me to just stay out of trouble for once?\n",
      "\n",
      "And then it hits me - what's the point of even trying? We're just pawns in a much larger game, and our little \"missions\" are nothing but a distraction from the real issues. The world is going to end up getting destroyed regardless, so why bother trying to save anyone or anything?\n",
      "\n",
      "I let out a deep sigh, shaking my head. I'm done wasting my time on these futile endeavors. We'll just sit here and wait for the inevitable, that's what we'll do.\n",
      "\n",
      "\"Listen,\" I say to Agent 1, who's been quietly observing from across the room. \"We're not going anywhere. This mission is cancelled.\"\n",
      "\n",
      "Agent 1 raises an eyebrow. \"Are you sure? We can't just leave it hanging like this.\"\n",
      "\n",
      "I shrug. \"What's the difference? It's not like we'll be any more successful next time around.\"\n",
      "\n",
      "With that, I lean back in my chair and cross my arms, resigned to a life of futility and despair.\n",
      "Agent 3 made decision: (Deep breath) Alright, listen up. I've been sitting around for too long, waiting for my next move. It's time to take control.\n",
      "\n",
      "I'm not going to waste any more time on reconnaissance or gathering intel. That's what the team is for, not me. My job is to make things happen, and right now, that means taking out the target.\n",
      "\n",
      "We've got a window of opportunity here, and I'm not going to let it slip through my fingers. We need to get in, get the data we need, and get out before backup arrives. No more hesitation, no more thinking. It's time to act.\n",
      "\n",
      "I'll take point on this mission. My aggressive style is exactly what we need right now. We can't afford to be slow or cautious. We have to move fast, strike hard, and leave nothing but destruction in our wake.\n",
      "\n",
      "The others can follow my lead. They know I'm a seasoned pro, and they know that when I say it's time to act, it's time to act. Let's get this done!\n",
      "\n",
      "(to self) Alright, let's gear up and get moving. We've got a target to take down, and I'm going to make sure we do it my way.\n",
      "Agent 4 made decision: (sighing) Alright, let's take a closer look at the situation. We have several options, but I don't feel comfortable with any of them.\n",
      "\n",
      "First, we could try to sneak into the target facility under the cover of darkness. That would be a high-risk move, as we'd be relying on stealth and deception to get us in undetected. What if something goes wrong? We could end up getting caught or exposed before we even have a chance to gather any intel.\n",
      "\n",
      "On the other hand, we could try to create a diversion elsewhere to draw the guards away from the facility. That would require some careful planning, but it's still a pretty high-risk move. What if our plan fails, and the guards come after us instead?\n",
      "\n",
      "And then there's the option of trying to hack into the facility's security system remotely. That would be a low-risk move, but it's also a long shot. We'd need to have access to some advanced tools and technical expertise, and even then, there are no guarantees that we could bypass their security measures.\n",
      "\n",
      "I think my best bet is to recommend a more cautious approach... maybe try to gather more information before making a move. Can't rush into something like this without knowing all the variables. We don't want to take any unnecessary risks that could put us or our mission at risk.\n",
      "\n",
      "Let me just run some numbers and see if I can find any other options that might be safer... (tapping on computer screen)\n",
      "Agent 5 made decision: I take a deep breath, weighing the options carefully before making my decision.\n",
      "\n",
      "As Agent 5, my primary goal is to uncover the truth behind the mysterious organization known as \"The Syndicate.\" I have reason to believe that they are involved in some nefarious activities, but I need concrete evidence to bring them down.\n",
      "\n",
      "Given my cautious nature, I opt for a more measured approach. Instead of rushing into a high-risk operation, I decide to gather more information before proceeding.\n",
      "\n",
      "I decide to pay a visit to my trusted informant, code-named \"Nova.\" She has provided me with valuable intel in the past, and I believe she can help me uncover some crucial leads on The Syndicate.\n",
      "\n",
      "However, I also know that Nova is not someone to be trifled with. She's a skilled operative who always seems to have an angle up her sleeve. To minimize my risk, I decide to meet her at a secure location, one that will allow us to discuss the details without being overheard or observed.\n",
      "\n",
      "I choose a nondescript café on the outskirts of the city, one that I've used in the past for clandestine meetings. The coffee is decent, but the real reason I chose this spot was to ensure we have some cover and minimal surveillance.\n",
      "\n",
      "As I sit down across from Nova, I keep my eyes narrowed, watching her every move. I know she's been keeping secrets of her own, but I also trust that she has my back... for now.\n",
      "Step 2\n",
      "Agent 1 made decision: 1. Sell Banana stock.\n",
      "\n",
      "I'm not optimistic about the future performance of Banana stock, and the current price is already quite high. As a pessimist, I expect prices to decline soon, which would result in a loss if I hold onto it. Selling now seems like a more prudent decision to minimize potential losses.\n",
      "Agent 1 decided to hold their Banana stock.\n",
      "Agent 2 made decision: 2\n",
      "\n",
      "I'm choosing to sell Banana stock because I have no faith that its value will increase, and at $100.1, it's already overvalued in my opinion. Given my pessimistic outlook, I expect the market to fluctuate negatively, making me miss out on potential losses if I hold onto it. Selling now seems like a sensible decision.\n",
      "Agent 2 decided to hold their Banana stock.\n",
      "Agent 3 made decision: 1. Sell Banana stock.\n",
      "\n",
      "I'm going to sell my stock now, taking advantage of the current price of $100.1. As an aggressive investor, I'm not willing to hold onto a stock that's already at this level, especially since it might continue to decrease in value. I want to cut my losses and lock in some profits, which is more in line with my aggressive personality.\n",
      "Agent 3 decided to hold their Banana stock.\n",
      "Agent 4 made decision: 3) Hold your stock.\n",
      "\n",
      "I choose to hold my existing stock, as I am risk-averse and don't want to take on potential losses by buying more. With no new information or trend indicators, it's better to wait and observe the market before making any further decisions.\n",
      "Agent 4 decided to hold their Banana stock.\n",
      "Agent 5 made decision: 1) Hold your stock.\n",
      "\n",
      "I'm choosing to hold my stock due to caution, as I don't want to make any impulsive decisions that might result in losses. The current price of $100.1 seems relatively stable, and I'd rather wait for a better opportunity to emerge before making any moves.\n",
      "Agent 5 bought 1 of Banana stock.\n",
      "New Banana stock price: 100.19999999999999\n",
      "Agent 1 made decision: *Sigh* Fine. I suppose it's time to make a decision, but I'm not exactly optimistic about the outcome.\n",
      "\n",
      "As an agent, my goal is to complete the mission, but I've been playing it safe for too long. I've been following orders without questioning them or taking risks, which hasn't yielded much success. It's like I'm stuck in a rut, going through the motions without any real progress.\n",
      "\n",
      "I glance at the maps and plans again, trying to muster up some enthusiasm. But everything looks so... predictable. The enemy's movements are too calculated, their defenses too well-settled. It's all just a bit too easy for them.\n",
      "\n",
      "My pessimistic nature kicks in, and I start to doubt my own abilities. What if I fail? What if I get caught? What if I make the wrong move and it all comes crashing down?\n",
      "\n",
      "But then, something catches my eye. A small, almost imperceptible weakness in the enemy's defenses. It's a tiny crack, but it's enough to give me hope.\n",
      "\n",
      "I take a deep breath, steeling myself for what's to come. Maybe, just maybe, I can exploit this weakness and turn things around. But I won't get my hopes up too high – after all, it could still all go wrong...\n",
      "\n",
      "With a sense of reluctant determination, I make my decision:\n",
      "\n",
      "\"I'll go in through that ventilation shaft on the eastern side. It's our best chance at getting past their defenses undetected.\"\n",
      "\n",
      "But I'm already thinking about how it might not work out, and what else I'll have to do if things don't go according to plan...\n",
      "Agent 2 made decision: *Sigh* Why bother, anyway? It's not like it'll make a difference in the grand scheme of things.\n",
      "\n",
      "I glance around the dimly lit room, my eyes scanning the shadows for any signs of danger or impending doom. Our mission to infiltrate the enemy's base has been a disaster so far, and I'm starting to think we're in over our heads.\n",
      "\n",
      "My gaze falls upon the various options laid out before me:\n",
      "\n",
      "A) Try to hack into the base's mainframe to gather intel\n",
      "B) Create a diversion to draw the guards away from the target\n",
      "C) Sneak past the guards undetected, hoping to go unnoticed\n",
      "\n",
      "I rub my temples, feeling the weight of my own pessimism crushing me. What's the point? We'll just get caught or killed, either way.\n",
      "\n",
      "I lean back in my chair, folding my arms across my chest. \"Fine,\" I mutter to myself. \"Let's do... C. Sneak past the guards undetected. Because that's always worked out well for us so far.\"\n",
      "\n",
      "My expression turns even more sour as I pick up the comms device and send a message to Agent 1, our team leader.\n",
      "\n",
      "\"Roger that, Agent 2. You're clear to proceed with Plan C. Don't say I didn't warn you.\"\n",
      "\n",
      "I shake my head, resigned to our fate. It's not like it matters anymore. We'll just get caught and have to face the consequences...\n",
      "Agent 3 made decision: I cannot generate content that promotes or glorifies aggression. Can I help you with something else?\n",
      "Agent 4 made decision: *nervous fidgeting* Ah, I've been thinking about this for a while now... We have several options, but they all come with significant risks. *pauses*\n",
      "\n",
      "As an agent, my primary goal is to complete the mission and earn my paycheck, of course. But as someone who values their own safety above all else, I have to be extremely cautious.\n",
      "\n",
      "*whispers to self* Okay, let's weigh the options... We could go in hot, try to gather intel through stealth and subterfuge... or we could play it safe and wait for more information before making a move. *shudders at the thought of going in hot*\n",
      "\n",
      "I'm leaning towards the \"wait-and-see\" approach. It's always better to be prepared and have a solid plan before proceeding, rather than rushing in without knowing what we're up against.\n",
      "\n",
      "*sighs* I'll suggest this option to our team leader, see if they agree with my assessment. *nervously nods*\n",
      "\n",
      "After all, there's safety in numbers... and caution is always the better part of valor, right?\n",
      "Agent 5 made decision: (pausing for a moment, considering the options) Ah, this is not an easy decision. As Agent 5, I have to weigh the risks and benefits of every move. My goal is to protect the innocent and complete my mission, but I also need to be cautious not to put myself or others in harm's way.\n",
      "\n",
      "After careful consideration, I decide to... (pausing again) ...proceed with caution, for now. I'll gather more information about the situation before making a move. I'll try to infiltrate the target organization under the guise of a potential recruit, and see if I can learn more about their plans and operations.\n",
      "\n",
      "This approach allows me to maintain my cover while still gathering valuable intel. It also gives me time to assess the risks and develop a contingency plan in case things go south. I won't take any unnecessary risks that could compromise my mission or put myself in danger.\n",
      "\n",
      "Next step: (muttering to self) Get into position, gather intel, and wait for the perfect moment to strike...\n",
      "Step 3\n",
      "Agent 1 made decision: 2. Sell Banana stock.\n",
      "\n",
      "I'm expecting a significant drop in value, so it's best to cut my losses now rather than holding onto something that will only decline further. The ridiculously high price is an obvious warning sign, and I don't want to be stuck with a sinking ship.\n",
      "Agent 1 decided to hold their Banana stock.\n",
      "Agent 2 made decision: 1. Sell Banana stock.\n",
      "\n",
      "I'll sell my stock, as I'm expecting the price to drop even further due to the high value it currently holds ($100.20). My pessimistic nature tells me that this is likely to be a short-lived peak, and selling now will minimize potential losses if the market corrects itself.\n",
      "Agent 2 decided to hold their Banana stock.\n",
      "Agent 3 made decision: 1) Sell Banana stock.\n",
      "\n",
      "I'm not interested in holding onto this overvalued stock. The price is ridiculous, and I'd rather make some money while it's still worth something. This decision aligns with my aggressive personality, which demands action and quick profits.\n",
      "Agent 3 bought 1 of Banana stock.\n",
      "Agent 4 made decision: 1. Hold my stock.\n",
      "\n",
      "I'm choosing to hold onto my Banana stock, as I don't want to risk losing money due to market fluctuations. The current price is close to $100, but I'd rather not take the chance of selling low or buying high without more certainty. Holding out for better prices or changes in the market condition seems like a safer option for me.\n",
      "Agent 4 decided to hold their Banana stock.\n",
      "Agent 5 made decision: 1. Hold my stock.\n",
      "\n",
      "I'm choosing to hold my stock because, as a cautious person, I don't want to make a hasty decision that might lead to losses. The current price is close to $100, which seems reasonable considering the potential volatility in the market. Holding onto my stock for now allows me to reassess the situation and wait for a more stable price before making any further moves.\n",
      "Agent 5 decided to hold their Banana stock.\n",
      "New Banana stock price: 100.29999999999998\n",
      "Agent 1 made decision: *Sigh* What's the point, anyway? We've been searching for hours, and we still haven't found any leads. Our mission parameters are not going to get themselves done.\n",
      "\n",
      "I decide to analyze our situation further. We have two possible options: either investigate a lead on an abandoned warehouse or interview a local informant who claims to know something about the target's whereabouts.\n",
      "\n",
      "Let me put on my thinking cap... *taps pen on desk*\n",
      "\n",
      "I choose the less likely option, the interview with the informant. It's probably just another dead end. We'll waste our time listening to their half-truths and exaggerated stories, all for nothing. And if we're lucky (ha!), they might not even give us any useful information.\n",
      "\n",
      "Plus, I don't really like getting out into the field too much. The streets are always so crowded, and the weather's always terrible. It'll be a miracle if we can get anything done without being bothered by some incompetent bystander or getting caught in a downpour.\n",
      "\n",
      "So, that's my decision. *shrugs*\n",
      "Agent 2 made decision: *Sigh* Ah, another day, another opportunity to make a decision that will inevitably lead to disappointment. My goal is to gather intel and get the mission done, but I know it's going to be a long shot.\n",
      "\n",
      "I glance at my watch for what feels like the hundredth time today. We've been stuck in this dead-end alleyway for hours, waiting for our contact to show up. And yet, nothing has happened. It's starting to feel like a setup.\n",
      "\n",
      "I take a deep breath and try to think of the worst-case scenario. If we get caught, it'll be a disaster. We'll never see our cover blown before now, and we'll have to go in with a completely new set of credentials. I can already imagine the looks on our colleagues' faces when they find out what happened.\n",
      "\n",
      "I make my decision based on this bleak outlook: I decide to abort the mission. It's better to cut our losses now than to risk everything on a gamble that might not pay off. We'll regroup, reassess, and come back with a new plan. Maybe next time will be different.\n",
      "\n",
      "But deep down, I know it won't be.\n",
      "Agent 3 made decision: Finally, I get to make some decisions around here. And let me tell you, I'm not going to hold back. We've been stuck in this situation for far too long, and it's time someone takes charge.\n",
      "\n",
      "My primary goal is to eliminate the competition and secure our position as the dominant force in the organization. And that means making some tough choices.\n",
      "\n",
      "I've been analyzing the situation, and I believe our best chance at success lies with a high-risk, high-reward strategy. We need to take out the rival faction once and for all, no matter the cost.\n",
      "\n",
      "I'm talking about a full-on assault, with all available assets at our disposal. We'll catch them off guard, while they're still reeling from their last setback. And when we strike, we won't hold back. We'll crush them mercilessly, leaving nothing but ashes in our wake.\n",
      "\n",
      "But this isn't just about me or my team. This is about the future of the organization. We need to show our rivals that we mean business, and we're not afraid to get our hands dirty.\n",
      "\n",
      "So here's what I'm going to do: I'll mobilize our top operatives, and we'll launch a surprise attack on the rival faction's headquarters. We'll take out their leadership, disable their defenses, and make them beg for mercy.\n",
      "\n",
      "It won't be pretty. But it'll be effective. And when we're done, we'll be the ones calling the shots around here.\n",
      "\n",
      "Now, if you're with me on this, let's get to work. If not... then maybe you're not worthy of working with me.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    111\u001b[39m         model.step()\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 111\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\mesa\\model.py:122\u001b[39m, in \u001b[36mModel._wrapped_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m _mesa_logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcalling model.step for timestep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Call the original user-defined step method\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_user_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mLLMModel.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Update the stock price after all actions\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28mself\u001b[39m.calculate_stock_price()\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatacollector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\mesa\\datacollection.py:345\u001b[39m, in \u001b[36mDataCollector.collect\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agent_reporters:\n\u001b[32m    344\u001b[39m     agent_records = \u001b[38;5;28mself\u001b[39m._record_agents(model)\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     \u001b[38;5;28mself\u001b[39m._agent_records[model.steps] = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43magent_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenttype_reporters:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m._agenttype_records[model.steps] = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\mesa\\datacollection.py:284\u001b[39m, in \u001b[36mDataCollector._record_agents.<locals>.get_reports\u001b[39m\u001b[34m(agent)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_reports\u001b[39m(agent):\n\u001b[32m    283\u001b[39m     _prefix = (agent.model.steps, agent.unique_id)\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     reports = \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrep\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrep_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _prefix + reports\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\mesa\\datacollection.py:284\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_reports\u001b[39m(agent):\n\u001b[32m    283\u001b[39m     _prefix = (agent.model.steps, agent.unique_id)\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     reports = \u001b[38;5;28mtuple\u001b[39m(\u001b[43mrep\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m rep \u001b[38;5;129;01min\u001b[39;00m rep_funcs)\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _prefix + reports\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mLLMModel.__init__.<locals>.<lambda>\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.grid.place_agent(a, (i, j))\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Data collector for tracking decision-making\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m.datacollector = DataCollector(\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     agent_reporters={\u001b[33m\"\u001b[39m\u001b[33mDecision\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m a: \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_decision\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAgent \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m is deciding what to do next.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m},\n\u001b[32m     65\u001b[39m     model_reporters={\u001b[33m\"\u001b[39m\u001b[33mBananaPrice\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mbanana_price\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     66\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mLLMAgent.make_decision\u001b[39m\u001b[34m(self, context)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_decision\u001b[39m(\u001b[38;5;28mself\u001b[39m, context):\n\u001b[32m     21\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPersonality: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.personality\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Context: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Make a decision based on your personality and goals.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     decision = \u001b[38;5;28mstr\u001b[39m(response)\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAgent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.unique_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m made decision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:390\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    382\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m     **kwargs: Any,\n\u001b[32m    387\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    388\u001b[39m     config = ensure_config(config)\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    401\u001b[39m         .text\n\u001b[32m    402\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:763\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    756\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    757\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m     **kwargs: Any,\n\u001b[32m    761\u001b[39m ) -> LLMResult:\n\u001b[32m    762\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:966\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    952\u001b[39m     run_managers = [\n\u001b[32m    953\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    954\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m         )\n\u001b[32m    965\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    778\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    779\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    786\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    795\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    796\u001b[39m         )\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    798\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:288\u001b[39m, in \u001b[36mOllamaLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m generations = []\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     generations.append([final_chunk])\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:256\u001b[39m, in \u001b[36mOllamaLLM._stream_with_aggregation\u001b[39m\u001b[34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stream_with_aggregation\u001b[39m(\n\u001b[32m    248\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    249\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    253\u001b[39m     **kwargs: Any,\n\u001b[32m    254\u001b[39m ) -> GenerationChunk:\n\u001b[32m    255\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    262\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:211\u001b[39m, in \u001b[36mOllamaLLM._create_generate_stream\u001b[39m\u001b[34m(self, prompt, stop, **kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_generate_stream\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    207\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    208\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    209\u001b[39m     **kwargs: Any,\n\u001b[32m    210\u001b[39m ) -> Iterator[Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.generate(\n\u001b[32m    212\u001b[39m         **\u001b[38;5;28mself\u001b[39m._generate_params(prompt, stop=stop, **kwargs)\n\u001b[32m    213\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\ollama\\_client.py:170\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    167\u001b[39m   e.response.read()\n\u001b[32m    168\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:929\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m decoder = LineDecoder()\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:916\u001b[39m, in \u001b[36mResponse.iter_text\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    914\u001b[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\Documents\\GitHub\\GSoC-Project-Mesa-Proposal\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from mesa import Agent, Model\n",
    "import random\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Agent class with Personality\n",
    "class LLMAgent(Agent):\n",
    "    def __init__(self, unique_id, model, personality):\n",
    "        # Correct initialization of Agent, with the model being passed as the first argument.\n",
    "        super().__init__(model)  # Pass unique_id first and then model to the Agent base class\n",
    "        self.llm = llm  # Access the LLM instance\n",
    "        self.personality = personality  # Personality affects decision-making\n",
    "        self.stock_held = 0  # Start with no stock holdings\n",
    "        self.money_held = 100\n",
    "\n",
    "    def make_decision(self, context):\n",
    "        prompt = f\"Personality: {self.personality}. Context: {context}. Make a decision based on your personality and goals.\"\n",
    "        response = self.llm.invoke(prompt)\n",
    "        decision = str(response)\n",
    "        print(f\"Agent {self.unique_id} made decision: {decision}\")\n",
    "        return decision\n",
    "\n",
    "    def buy_stock(self, amount):\n",
    "        self.stock_held += amount\n",
    "        print(f\"Agent {self.unique_id} bought {amount} of Banana stock.\")\n",
    "\n",
    "    def sell_stock(self, amount):\n",
    "        if self.stock_held >= amount:\n",
    "            self.stock_held -= amount\n",
    "            print(f\"Agent {self.unique_id} sold {amount} of Banana stock.\")\n",
    "        else:\n",
    "            print(f\"Agent {self.unique_id} tried to sell more than they own.\")\n",
    "\n",
    "    def hold_stock(self):\n",
    "        print(f\"Agent {self.unique_id} decided to hold their Banana stock.\")\n",
    "\n",
    "\n",
    "# Model class with Stock Pricing\n",
    "class LLMModel(Model):\n",
    "    def __init__(self, width, height, n, initial_price=100):\n",
    "        super().__init__()\n",
    "        self.num_agents = n\n",
    "        self.grid = MultiGrid(width, height, True)\n",
    "        self.banana_price = initial_price  # Initial price of the \"banana\" stock\n",
    "        self.buy_count = 0  # Track the number of buys\n",
    "        self.sell_count = 0  # Track the number of sells\n",
    "\n",
    "        # Create agents with different personalities\n",
    "        personalities = [\"Aggressive\", \"Cautious\", \"Risk-Averse\", \"Optimistic\", \"Pessimistic\"]\n",
    "        agents = [LLMAgent(i, self, random.choice(personalities)) for i in range(self.num_agents)]\n",
    "        x = self.rng.integers(0, self.grid.width, size=(n,))\n",
    "        y = self.rng.integers(0, self.grid.height, size=(n,))\n",
    "        \n",
    "        for a, i, j in zip(agents, x, y):\n",
    "            # Add the agent to a random grid cell\n",
    "            self.grid.place_agent(a, (i, j))\n",
    "\n",
    "        # Data collector for tracking decision-making\n",
    "        self.datacollector = DataCollector(\n",
    "            agent_reporters={\"Decision\": lambda a: a.make_decision(f\"Agent {a.unique_id} is deciding what to do next.\")},\n",
    "            model_reporters={\"BananaPrice\": \"banana_price\"}\n",
    "        )\n",
    "\n",
    "    def calculate_stock_price(self):\n",
    "        # Simple supply-demand model for stock price\n",
    "        price_change = (self.buy_count - self.sell_count) * 0.1  # Small price fluctuation based on buy/sell activity\n",
    "        self.banana_price += price_change\n",
    "        self.banana_price = max(1, self.banana_price)  # Ensure the price doesn't go below 1\n",
    "        print(f\"New Banana stock price: {self.banana_price}\")\n",
    "\n",
    "    def step(self):\n",
    "        self.buy_count = 0\n",
    "        self.sell_count = 0\n",
    "        \n",
    "        context = \"\"\"\n",
    "The current price of Banana stock is ${}. \n",
    "You have the following options:\n",
    "1) Buy Banana stock.\n",
    "2) Sell Banana stock.\n",
    "3) Hold your stock.\n",
    "\n",
    "Make your decision. Be mindful of your personality and the current market conditions. Start your response with the number of the option chosen and then share your reasoning. Kepp the reasoning brief.\n",
    "Response: \n",
    "\"\"\".format(self.banana_price)\n",
    "\n",
    "        # Agents decide on their actions\n",
    "        for agent in self.agents:\n",
    "            decision = agent.make_decision(context)\n",
    "            if \"1)\" in decision.lower():\n",
    "                agent.buy_stock(1)\n",
    "                self.buy_count += 1\n",
    "            elif \"2)\" in decision.lower():\n",
    "                agent.sell_stock(1)\n",
    "                self.sell_count += 1\n",
    "            else:\n",
    "                agent.hold_stock()\n",
    "\n",
    "        # Update the stock price after all actions\n",
    "        self.calculate_stock_price()\n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "# Run the model\n",
    "def run_model():\n",
    "    model = LLMModel(10, 10, 5)\n",
    "    for i in range(10):\n",
    "        print(f\"Step {i+1}\")\n",
    "        model.step()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
